Title: Reinforcement Learning with Human Feedback for Realistic Traffic  Simulation
In light of the challenges and costs of real-world testing, autonomous
vehicle developers often rely on testing in simulation for the creation of
reliable systems. A key element of effective simulation is the incorporation of
realistic traffic models that align with human knowledge, an aspect that has
proven challenging due to the need to balance realism and diversity. This works
aims to address this by developing a framework that employs reinforcement
learning with human preference (RLHF) to enhance the realism of existing
traffic models. This study also identifies two main challenges: capturing the
nuances of human preferences on realism and the unification of diverse traffic
simulation models. To tackle these issues, we propose using human feedback for
alignment and employ RLHF due to its sample efficiency. We also introduce the
first dataset for realism alignment in traffic modeling to support such
research. Our framework, named TrafficRLHF, demonstrates its proficiency in
generating realistic traffic scenarios that are well-aligned with human
preferences, as corroborated by comprehensive evaluations on the nuScenes
dataset.



Title: Zero-Shot Recommendations with Pre-Trained Large Language Models for  Multimodal Nudging
We present a method for zero-shot recommendation of multimodal non-stationary
content that leverages recent advancements in the field of generative AI. We
propose rendering inputs of different modalities as textual descriptions and to
utilize pre-trained LLMs to obtain their numerical representations by computing
semantic embeddings. Once unified representations of all content items are
obtained, the recommendation can be performed by computing an appropriate
similarity metric between them without any additional learning. We demonstrate
our approach on a synthetic multimodal nudging environment, where the inputs
consist of tabular, textual, and visual data.



Title: Neurosymbolic Reinforcement Learning and Planning: A Survey
The area of Neurosymbolic Artificial Intelligence (Neurosymbolic AI) is
rapidly developing and has become a popular research topic, encompassing
sub-fields such as Neurosymbolic Deep Learning (Neurosymbolic DL) and
Neurosymbolic Reinforcement Learning (Neurosymbolic RL). Compared to
traditional learning methods, Neurosymbolic AI offers significant advantages by
simplifying complexity and providing transparency and explainability.
Reinforcement Learning(RL), a long-standing Artificial Intelligence(AI) concept
that mimics human behavior using rewards and punishment, is a fundamental
component of Neurosymbolic RL, a recent integration of the two fields that has
yielded promising results. The aim of this paper is to contribute to the
emerging field of Neurosymbolic RL by conducting a literature survey. Our
evaluation focuses on the three components that constitute Neurosymbolic RL:
neural, symbolic, and RL. We categorize works based on the role played by the
neural and symbolic parts in RL, into three taxonomies:Learning for Reasoning,
Reasoning for Learning and Learning-Reasoning. These categories are further
divided into sub-categories based on their applications. Furthermore, we
analyze the RL components of each research work, including the state space,
action space, policy module, and RL algorithm. Additionally, we identify
research opportunities and challenges in various applications within this
dynamic field.



Title: A Study on the Implementation of Generative AI Services Using an  Enterprise Data-Based LLM Application Architecture
This study presents a method for implementing generative AI services by
utilizing the Large Language Model (LLM) application architecture. With recent
advancements in generative AI technology, LLMs have gained prominence across
various domains. In this context, the research addresses the challenge of
information scarcity and proposes specific remedies by harnessing LLM
capabilities. The investigation delves into strategies for mitigating the issue
of inadequate data, offering tailored solutions. The study delves into the
efficacy of employing fine-tuning techniques and direct document integration to
alleviate data insufficiency. A significant contribution of this work is the
development of a Retrieval-Augmented Generation (RAG) model, which tackles the
aforementioned challenges. The RAG model is carefully designed to enhance
information storage and retrieval processes, ensuring improved content
generation. The research elucidates the key phases of the information storage
and retrieval methodology underpinned by the RAG model. A comprehensive
analysis of these steps is undertaken, emphasizing their significance in
addressing the scarcity of data. The study highlights the efficacy of the
proposed method, showcasing its applicability through illustrative instances.
By implementing the RAG model for information storage and retrieval, the
research not only contributes to a deeper comprehension of generative AI
technology but also facilitates its practical usability within enterprises
utilizing LLMs. This work holds substantial value in advancing the field of
generative AI, offering insights into enhancing data-driven content generation
and fostering active utilization of LLM-based services within corporate
settings.



Title: Logic of subjective probability
In this paper I discuss both syntax and semantics of subjective probability.
The semantics determines ways of testing probability statements. Among
important varieties of subjective probabilities are intersubjective
probabilities and impersonal probabilities, and I will argue that well-tested
impersonal probabilities acquire features of objective probabilities.
Jeffreys's law, my next topic, states that two successful probability
forecasters must issue forecasts that are close to each other, thus supporting
the idea of objective probabilities. Finally, I will discuss connections
between subjective and frequentist probability.



Title: A Survey on Service Route and Time Prediction in Instant Delivery:  Taxonomy, Progress, and Prospects
Instant delivery services, such as food delivery and package delivery, have
achieved explosive growth in recent years by providing customers with
daily-life convenience. An emerging research area within these services is
service Route\&Time Prediction (RTP), which aims to estimate the future service
route as well as the arrival time of a given worker. As one of the most crucial
tasks in those service platforms, RTP stands central to enhancing user
satisfaction and trimming operational expenditures on these platforms. Despite
a plethora of algorithms developed to date, there is no systematic,
comprehensive survey to guide researchers in this domain. To fill this gap, our
work presents the first comprehensive survey that methodically categorizes
recent advances in service route and time prediction. We start by defining the
RTP challenge and then delve into the metrics that are often employed.
Following that, we scrutinize the existing RTP methodologies, presenting a
novel taxonomy of them. We categorize these methods based on three criteria:
(i) type of task, subdivided into only-route prediction, only-time prediction,
and joint route\&time prediction; (ii) model architecture, which encompasses
sequence-based and graph-based models; and (iii) learning paradigm, including
Supervised Learning (SL) and Deep Reinforcement Learning (DRL). Conclusively,
we highlight the limitations of current research and suggest prospective
avenues. We believe that the taxonomy, progress, and prospects introduced in
this paper can significantly promote the development of this field.



Title: Large AI Model Empowered Multimodal Semantic Communications
Multimodal signals, including text, audio, image and video, can be integrated
into Semantic Communication (SC) for providing an immersive experience with low
latency and high quality at the semantic level. However, the multimodal SC has
several challenges, including data heterogeneity, semantic ambiguity, and
signal fading. Recent advancements in large AI models, particularly in
Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential
solutions for these issues. To this end, we propose a Large AI Model-based
Multimodal SC (LAM-MSC) framework, in which we first present the MLM-based
Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation
between multimodal and unimodal data while preserving semantic consistency.
Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows
users to perform personalized semantic extraction or recovery through the LLM.
This effectively addresses the semantic ambiguity. Finally, we apply the
Conditional Generative adversarial networks-based channel Estimation (CGE) to
obtain Channel State Information (CSI). This approach effectively mitigates the
impact of fading channels in SC. Finally, we conduct simulations that
demonstrate the superior performance of the LAM-MSC framework.



Title: AlphaZero Gomoku
In the past few years, AlphaZero's exceptional capability in mastering
intricate board games has garnered considerable interest. Initially designed
for the game of Go, this revolutionary algorithm merges deep learning
techniques with the Monte Carlo tree search (MCTS) to surpass earlier top-tier
methods. In our study, we broaden the use of AlphaZero to Gomoku, an age-old
tactical board game also referred to as "Five in a Row." Intriguingly, Gomoku
has innate challenges due to a bias towards the initial player, who has a
theoretical advantage. To add value, we strive for a balanced game-play. Our
tests demonstrate AlphaZero's versatility in adapting to games other than Go.
MCTS has become a predominant algorithm for decision processes in intricate
scenarios, especially board games. MCTS creates a search tree by examining
potential future actions and uses random sampling to predict possible results.
By leveraging the best of both worlds, the AlphaZero technique fuses deep
learning from Reinforcement Learning with the balancing act of MCTS,
establishing a fresh standard in game-playing AI. Its triumph is notably
evident in board games such as Go, chess, and shogi.



Title: ChatRule: Mining Logical Rules with Large Language Models for Knowledge  Graph Reasoning
Logical rules are essential for uncovering the logical connections between
relations, which could improve the reasoning performance and provide
interpretable results on knowledge graphs (KGs). Although there have been many
efforts to mine meaningful logical rules over KGs, existing methods suffer from
the computationally intensive searches over the rule space and a lack of
scalability for large-scale KGs. Besides, they often ignore the semantics of
relations which is crucial for uncovering logical connections. Recently, large
language models (LLMs) have shown impressive performance in the field of
natural language processing and various applications, owing to their emergent
ability and generalizability. In this paper, we propose a novel framework,
ChatRule, unleashing the power of large language models for mining logical
rules over knowledge graphs. Specifically, the framework is initiated with an
LLM-based rule generator, leveraging both the semantic and structural
information of KGs to prompt LLMs to generate logical rules. To refine the
generated rules, a rule ranking module estimates the rule quality by
incorporating facts from existing KGs. Last, a rule validator harnesses the
reasoning ability of LLMs to validate the logical correctness of ranked rules
through chain-of-thought reasoning. ChatRule is evaluated on four large-scale
KGs, w.r.t. different rule quality metrics and downstream tasks, showing the
effectiveness and scalability of our method.



Title: Concepts is All You Need: A More Direct Path to AGI
Little demonstrable progress has been made toward AGI (Artificial General
Intelligence) since the term was coined some 20 years ago. In spite of the
fantastic breakthroughs in Statistical AI such as AlphaZero, ChatGPT, and
Stable Diffusion none of these projects have, or claim to have, a clear path to
AGI. In order to expedite the development of AGI it is crucial to understand
and identify the core requirements of human-like intelligence as it pertains to
AGI. From that one can distill which particular development steps are necessary
to achieve AGI, and which are a distraction. Such analysis highlights the need
for a Cognitive AI approach rather than the currently favored statistical and
generative efforts. More specifically it identifies the central role of
concepts in human-like cognition. Here we outline an architecture and
development plan, together with some preliminary results, that offers a much
more direct path to full Human-Level AI (HLAI)/ AGI.



Title: A Survey on Interpretable Cross-modal Reasoning
In recent years, cross-modal reasoning (CMR), the process of understanding
and reasoning across different modalities, has emerged as a pivotal area with
applications spanning from multimedia analysis to healthcare diagnostics. As
the deployment of AI systems becomes more ubiquitous, the demand for
transparency and comprehensibility in these systems' decision-making processes
has intensified. This survey delves into the realm of interpretable cross-modal
reasoning (I-CMR), where the objective is not only to achieve high predictive
performance but also to provide human-understandable explanations for the
results. This survey presents a comprehensive overview of the typical methods
with a three-level taxonomy for I-CMR. Furthermore, this survey reviews the
existing CMR datasets with annotations for explanations. Finally, this survey
summarizes the challenges for I-CMR and discusses potential future directions.
In conclusion, this survey aims to catalyze the progress of this emerging
research area by providing researchers with a panoramic and comprehensive
perspective, illuminating the state of the art and discerning the
opportunities.



Title: Belief revision and incongruity: is it a joke?
Incongruity often makes people laugh. You have to be smart to say stupid
things. It requires to be even smarter for understanding them. This paper is a
shameless attempt to formalize this intelligent behavior in the case of an
agent listening to a joke. All this is a matter of revision of beliefs,
surprise and violation of norms.



Title: Optimal Observation-Intervention Trade-Off in Optimisation Problems with  Causal Structure
We consider the problem of optimising an expensive-to-evaluate grey-box
objective function, within a finite budget, where known side-information exists
in the form of the causal structure between the design variables. Standard
black-box optimisation ignores the causal structure, often making it
inefficient and expensive. The few existing methods that consider the causal
structure are myopic and do not fully accommodate the observation-intervention
trade-off that emerges when estimating causal effects. In this paper, we show
that the observation-intervention trade-off can be formulated as a non-myopic
optimal stopping problem which permits an efficient solution. We give
theoretical results detailing the structure of the optimal stopping times and
demonstrate the generality of our approach by showing that it can be integrated
with existing causal Bayesian optimisation algorithms. Experimental results
show that our formulation can enhance existing algorithms on real and synthetic
benchmarks.



Title: Cognitive Architectures for Language Agents
Recent efforts have incorporated large language models (LLMs) with external
resources (e.g., the Internet) or internal control flows (e.g., prompt
chaining) for tasks requiring grounding or reasoning. However, these efforts
have largely been piecemeal, lacking a systematic framework for constructing a
fully-fledged language agent. To address this challenge, we draw on the rich
history of agent design in symbolic artificial intelligence to develop a
blueprint for a new wave of cognitive language agents. We first show that LLMs
have many of the same properties as production systems, and recent efforts to
improve their grounding or reasoning mirror the development of cognitive
architectures built around production systems. We then propose Cognitive
Architectures for Language Agents (CoALA), a conceptual framework to
systematize diverse methods for LLM-based reasoning, grounding, learning, and
decision making as instantiations of language agents in the framework. Finally,
we use the CoALA framework to highlight gaps and propose actionable directions
toward more capable language agents in the future.



Title: Video based Object 6D Pose Estimation using Transformers
We introduce a Transformer based 6D Object Pose Estimation framework
VideoPose, comprising an end-to-end attention based modelling architecture,
that attends to previous frames in order to estimate accurate 6D Object Poses
in videos. Our approach leverages the temporal information from a video
sequence for pose refinement, along with being computationally efficient and
robust. Compared to existing methods, our architecture is able to capture and
reason from long-range dependencies efficiently, thus iteratively refining over
video sequences. Experimental evaluation on the YCB-Video dataset shows that
our approach is on par with the state-of-the-art Transformer methods, and
performs significantly better relative to CNN based approaches. Further, with a
speed of 33 fps, it is also more efficient and therefore applicable to a
variety of applications that require real-time object pose estimation. Training
code and pretrained models are available at
https://github.com/ApoorvaBeedu/VideoPose



Title: Through their eyes: multi-subject Brain Decoding with simple alignment  techniques
Previous brain decoding research primarily involves single-subject studies,
reconstructing stimuli via fMRI activity from the same subject. Our study aims
to introduce a generalization technique for cross-subject brain decoding,
facilitated by exploring data alignment methods. We utilized the NSD dataset, a
comprehensive 7T fMRI vision experiment involving multiple subjects exposed to
9841 images, 982 of which were viewed by all. Our approach involved training a
decoding model on one subject, aligning others' data to this space, and testing
the decoding on the second subject. We compared ridge regression, hyper
alignment, and anatomical alignment techniques for fMRI data alignment. We
established that cross-subject brain decoding is feasible, even using around
10% of the total data, or 982 common images, with comparable performance to
single-subject decoding. Ridge regression was the best method for functional
alignment. Through subject alignment, we achieved superior brain decoding and a
potential 90% reduction in scan time. This could pave the way for more
efficient experiments and further advancements in the field, typically
requiring an exorbitant 20-hour scan time per subject.



Title: Generative AI for End-to-End Limit Order Book Modelling: A Token-Level  Autoregressive Generative Model of Message Flow Using a Deep State Space  Network
Developing a generative model of realistic order flow in financial markets is
a challenging open problem, with numerous applications for market participants.
Addressing this, we propose the first end-to-end autoregressive generative
model that generates tokenized limit order book (LOB) messages. These messages
are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle
long sequences efficiently, the model employs simplified structured state-space
layers to process sequences of order book states and tokenized messages. Using
LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message
data, converting groups of successive digits to tokens, similar to tokenization
in large language models. Out-of-sample results show promising performance in
approximating the data distribution, as evidenced by low model perplexity.
Furthermore, the mid-price returns calculated from the generated order flow
exhibit a significant correlation with the data, indicating impressive
conditional forecast performance. Due to the granularity of generated data, and
the accuracy of the model, it offers new application areas for future work
beyond forecasting, e.g. acting as a world model in high-frequency financial
reinforcement learning applications. Overall, our results invite the use and
extension of the model in the direction of autoregressive large financial
models for the generation of high-frequency financial data and we commit to
open-sourcing our code to facilitate future research.



Title: Ten New Benchmarks for Optimization
Benchmarks are used for testing new optimization algorithms and their
variants to evaluate their performance. Most existing benchmarks are smooth
functions. This chapter introduces ten new benchmarks with different
properties, including noise, discontinuity, parameter estimation and unknown
paths.



Title: Intelligence as a Measure of Consciousness
Evaluating artificial systems for signs of consciousness is increasingly
becoming a pressing concern, and a rigorous psychometric measurement framework
may be of crucial importance in evaluating large language models in this
regard. Most prominent theories of consciousness, both scientific and
metaphysical, argue for different kinds of information coupling as a necessary
component of human-like consciousness. By comparing information coupling in
human and animal brains, human cognitive development, emergent abilities, and
mental representation development to analogous phenomena in large language
models, I argue that psychometric measures of intelligence, such as the
g-factor or IQ, indirectly approximate the extent of conscious experience. Based on a broader source of both scientific and metaphysical theories of
consciousness, I argue that all systems possess a degree of consciousness
ascertainable psychometrically and that psychometric measures of intelligence
may be used to gauge relative similarities of conscious experiences across
disparate systems, be they artificial or human.



Title: GPT has become financially literate: Insights from financial literacy  tests of GPT and a preliminary test of how people use it as a source of  advice
We assess the ability of GPT -- a large language model -- to serve as a
financial robo-advisor for the masses, by using a financial literacy test.
Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial
literacy test, respectively, compared to a baseline of 33%. However, ChatGPT
based on GPT-4 achieves a near-perfect 99% score, pointing to financial
literacy becoming an emergent ability of state-of-the-art models. We use the
Judge-Advisor System and a savings dilemma to illustrate how researchers might
assess advice-utilization from large language models. We also present a number
of directions for future research.



Title: The Use of Synthetic Data to Train AI Models: Opportunities and Risks  for Sustainable Development
In the current data driven era, synthetic data, artificially generated data
that resembles the characteristics of real world data without containing actual
personal information, is gaining prominence. This is due to its potential to
safeguard privacy, increase the availability of data for research, and reduce
bias in machine learning models. This paper investigates the policies governing
the creation, utilization, and dissemination of synthetic data. Synthetic data
can be a powerful instrument for protecting the privacy of individuals, but it
also presents challenges, such as ensuring its quality and authenticity. A well
crafted synthetic data policy must strike a balance between privacy concerns
and the utility of data, ensuring that it can be utilized effectively without
compromising ethical or legal standards. Organizations and institutions must
develop standardized guidelines and best practices in order to capitalize on
the benefits of synthetic data while addressing its inherent challenges.



Title: ICDARTS: Improving the Stability and Performance of Cyclic DARTS
This work introduces improvements to the stability and generalizability of
Cyclic DARTS (CDARTS). CDARTS is a Differentiable Architecture Search
(DARTS)-based approach to neural architecture search (NAS) that uses a cyclic
feedback mechanism to train search and evaluation networks concurrently. This
training protocol aims to optimize the search process by enforcing that the
search and evaluation networks produce similar outputs. However, CDARTS
introduces a loss function for the evaluation network that is dependent on the
search network. The dissimilarity between the loss functions used by the
evaluation networks during the search and retraining phases results in a
search-phase evaluation network that is a sub-optimal proxy for the final
evaluation network that is utilized during retraining. We present ICDARTS, a
revised approach that eliminates the dependency of the evaluation network
weights upon those of the search network, along with a modified process for
discretizing the search network's \textit{zero} operations that allows these
operations to be retained in the final evaluation networks. We pair the results
of these changes with ablation studies on ICDARTS' algorithm and network
template. Finally, we explore methods for expanding the search space of ICDARTS
by expanding its operation set and exploring alternate methods for discretizing
its continuous search cells. These experiments resulted in networks with
improved generalizability and the implementation of a novel method for
incorporating a dynamic search space into ICDARTS.



Title: Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic  Learning
Federated and Continual Learning have emerged as potential paradigms for the
robust and privacy-aware use of Deep Learning in dynamic environments. However,
Client Drift and Catastrophic Forgetting are fundamental obstacles to
guaranteeing consistent performance. Existing work only addresses these
problems separately, which neglects the fact that the root cause behind both
forms of performance deterioration is connected. We propose a unified analysis
framework for building a controlled test environment for Client Drift -- by
perturbing a defined ratio of clients -- and Catastrophic Forgetting -- by
shifting all clients with a particular strength. Our framework further
leverages this new combined analysis by generating a 3D landscape of the
combined performance impact from both. We demonstrate that the performance drop
through Client Drift, caused by a certain share of shifted clients, is
correlated to the drop from Catastrophic Forgetting resulting from a
corresponding shift strength. Correlation tests between both problems for
Computer Vision (CelebA) and Medical Imaging (PESO) support this new
perspective, with an average Pearson rank correlation coefficient of over 0.94.
Our framework's novel ability of combined spatio-temporal shift analysis allows
us to investigate how both forms of distribution shift behave in mixed
scenarios, opening a new pathway for better generalization. We show that a
combination of moderate Client Drift and Catastrophic Forgetting can even
improve the performance of the resulting model (causing a "Generalization
Bump") compared to when only one of the shifts occurs individually. We apply a
simple and commonly used method from Continual Learning in the federated
setting and observe this phenomenon to be reoccurring, leveraging the ability
of our framework to analyze existing and novel methods for Federated and
Continual Learning.



Title: Geometric Deep Learning: a Temperature Based Analysis of Graph Neural  Networks
We examine a Geometric Deep Learning model as a thermodynamic system treating
the weights as non-quantum and non-relativistic particles. We employ the notion
of temperature previously defined in [7] and study it in the various layers for
GCN and GAT models. Potential future applications of our findings are
discussed.



Title: Contextual Biasing of Named-Entities with Large Language Models
This paper studies contextual biasing with Large Language Models (LLMs),
where during second-pass rescoring additional contextual information is
provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We
propose to leverage prompts for a LLM without fine tuning during rescoring
which incorporate a biasing list and few-shot examples to serve as additional
information when calculating the score for the hypothesis. In addition to
few-shot prompt learning, we propose multi-task training of the LLM to predict
both the entity class and the next token. To improve the efficiency for
contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we
propose dynamic prompting, where we select the most likely class using the
class tag prediction, and only use entities in this class as contexts for next
token prediction. Word Error Rate (WER) evaluation is performed on i) an
internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli
dataset. Results indicate that biasing lists and few-shot examples can achieve
17.8% and 9.6% relative improvement compared to first pass ASR, and that
multi-task training and dynamic prompting can achieve 20.0% and 11.3% relative
WER improvement, respectively.



Title: Language-Conditioned Change-point Detection to Identify Sub-Tasks in  Robotics Domains
In this work, we present an approach to identify sub-tasks within a
demonstrated robot trajectory using language instructions. We identify these
sub-tasks using language provided during demonstrations as guidance to identify
sub-segments of a longer robot trajectory. Given a sequence of natural language
instructions and a long trajectory consisting of image frames and discrete
actions, we want to map an instruction to a smaller fragment of the trajectory.
Unlike previous instruction following works which directly learn the mapping
from language to a policy, we propose a language-conditioned change-point
detection method to identify sub-tasks in a problem. Our approach learns the
relationship between constituent segments of a long language command and
corresponding constituent segments of a trajectory. These constituent
trajectory segments can be used to learn subtasks or sub-goals for planning or
options as demonstrated by previous related work. Our insight in this work is
that the language-conditioned robot change-point detection problem is similar
to the existing video moment retrieval works used to identify sub-segments
within online videos. Through extensive experimentation, we demonstrate a
$1.78_{\pm 0.82}\%$ improvement over a baseline approach in accurately
identifying sub-tasks within a trajectory using our proposed method. Moreover,
we present a comprehensive study investigating sample complexity requirements
on learning this mapping, between language and trajectory sub-segments, to
understand if the video retrieval-based methods are realistic in real robot
scenarios.



Title: Efficient RLHF: Reducing the Memory Usage of PPO
Reinforcement Learning with Human Feedback (RLHF) has revolutionized language
modeling by aligning models with human preferences. However, the RL stage,
Proximal Policy Optimization (PPO), requires over 3x the memory of Supervised
Fine-Tuning (SFT), making it infeasible to use for most practitioners. To
address this issue, we present a comprehensive analysis the memory usage,
performance, and training time of memory-savings techniques for PPO. We
introduce Hydra-RLHF by first integrating the SFT and Reward models and then
dynamically turning LoRA "off" during training. Our experiments show: 1. Using
LoRA during PPO reduces its memory usage to be smaller than SFT while improving
alignment across four public benchmarks, and 2. Hydra-PPO reduces the latency
per sample of LoRA-PPO by up to 65% while maintaining its performance. Our
results demonstrate that Hydra-PPO is a simple and promising solution for
enabling more widespread usage of RLHF.



Title: Bias and Fairness in Large Language Models: A Survey
Rapid advancements of large language models (LLMs) have enabled the
processing, understanding, and generation of human-like text, with increasing
integration into systems that touch our social sphere. Despite this success,
these models can learn, perpetuate, and amplify harmful social biases. In this
paper, we present a comprehensive survey of bias evaluation and mitigation
techniques for LLMs. We first consolidate, formalize, and expand notions of
social bias and fairness in natural language processing, defining distinct
facets of harm and introducing several desiderata to operationalize fairness
for LLMs. We then unify the literature by proposing three intuitive taxonomies,
two for bias evaluation, namely metrics and datasets, and one for mitigation.
Our first taxonomy of metrics for bias evaluation disambiguates the
relationship between metrics and evaluation datasets, and organizes metrics by
the different levels at which they operate in a model: embeddings,
probabilities, and generated text. Our second taxonomy of datasets for bias
evaluation categorizes datasets by their structure as counterfactual inputs or
prompts, and identifies the targeted harms and social groups; we also release a
consolidation of publicly-available datasets for improved access. Our third
taxonomy of techniques for bias mitigation classifies methods by their
intervention during pre-processing, in-training, intra-processing, and
post-processing, with granular subcategories that elucidate research trends.
Finally, we identify open problems and challenges for future work. Synthesizing
a wide range of recent research, we aim to provide a clear guide of the
existing literature that empowers researchers and practitioners to better
understand and prevent the propagation of bias in LLMs.



Title: Contrastive Feature Masking Open-Vocabulary Vision Transformer
We present Contrastive Feature Masking Vision Transformer (CFM-ViT) - an
image-text pretraining methodology that achieves simultaneous learning of
image- and region-level representation for open-vocabulary object detection
(OVD). Our approach combines the masked autoencoder (MAE) objective into the
contrastive learning objective to improve the representation for localization
tasks. Unlike standard MAE, we perform reconstruction in the joint image-text
embedding space, rather than the pixel space as is customary with the classical
MAE method, which causes the model to better learn region-level semantics.
Moreover, we introduce Positional Embedding Dropout (PED) to address scale
variation between image-text pretraining and detection finetuning by randomly
dropping out the positional embeddings during pretraining. PED improves
detection performance and enables the use of a frozen ViT backbone as a region
classifier, preventing the forgetting of open-vocabulary knowledge during
detection finetuning. On LVIS open-vocabulary detection benchmark, CFM-ViT
achieves a state-of-the-art 33.9 AP$r$, surpassing the best approach by 7.6
points and achieves better zero-shot detection transfer. Finally, CFM-ViT
acquires strong image-level representation, outperforming the state of the art
on 8 out of 12 metrics on zero-shot image-text retrieval benchmarks.



Title: Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights,  and Duties
Human values are crucial to human decision-making. Value pluralism is the
view that multiple correct values may be held in tension with one another
(e.g., when considering lying to a friend to protect their feelings, how does
one balance honesty with friendship?). As statistical learners, AI systems fit
to averages by default, washing out these potentially irreducible value
conflicts. To improve AI systems to better reflect value pluralism, the
first-order challenge is to explore the extent to which AI systems can model
pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and
duties connected to 31k human-written situations. ValuePrism's contextualized
values are generated by GPT-4 and deemed high-quality by human annotators 91%
of the time. We conduct a large-scale study with annotators across diverse
social and demographic backgrounds to try to understand whose values are
represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured
language-based multi-task model that generates, explains, and assesses the
relevance and valence (i.e., support or oppose) of human values, rights, and
duties within a specific context. Humans prefer the sets of values output by
our system over the teacher GPT-4, finding them more accurate and with broader
coverage. In addition, we demonstrate that Kaleido can help explain variability
in human decision-making by outputting contrasting values. Finally, we show
that Kaleido's representations transfer to other philosophical frameworks and
datasets, confirming the benefit of an explicit, modular, and interpretable
approach to value pluralism. We hope that our work will serve as a step to
making more explicit the implicit values behind human decision-making and to
steering AI systems to make decisions that are more in accordance with them.



Title: RenAIssance: A Survey into AI Text-to-Image Generation in the Era of  Large Model
Text-to-image generation (TTI) refers to the usage of models that could
process text input and generate high fidelity images based on text
descriptions. Text-to-image generation using neural networks could be traced
back to the emergence of Generative Adversial Network (GAN), followed by the
autoregressive Transformer. Diffusion models are one prominent type of
generative model used for the generation of images through the systematic
introduction of noises with repeating steps. As an effect of the impressive
results of diffusion models on image synthesis, it has been cemented as the
major image decoder used by text-to-image models and brought text-to-image
generation to the forefront of machine-learning (ML) research. In the era of
large models, scaling up model size and the integration with large language
models have further improved the performance of TTI models, resulting the
generation result nearly indistinguishable from real-world images,
revolutionizing the way we retrieval images. Our explorative study has
incentivised us to think that there are further ways of scaling text-to-image
models with the combination of innovative model architectures and prediction
enhancement techniques. We have divided the work of this survey into five main
sections wherein we detail the frameworks of major literature in order to delve
into the different types of text-to-image generation methods. Following this we
provide a detailed comparison and critique of these methods and offer possible
pathways of improvement for future work. In the future work, we argue that TTI
development could yield impressive productivity improvements for creation,
particularly in the context of the AIGC era, and could be extended to more
complex tasks such as video generation and 3D generation.



Title: Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual  Bandits
We consider the adversarial linear contextual bandit problem, where the loss
vectors are selected fully adversarially and the per-round action set (i.e. the
context) is drawn from a fixed distribution. Existing methods for this problem
either require access to a simulator to generate free i.i.d. contexts, achieve
a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6}})$, or are
computationally inefficient. We greatly improve these results by achieving a
regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining
computational efficiency when the action set in each round is small. In the
special case of sleeping bandits with adversarial loss and stochastic arm
availability, our result answers affirmatively the open question by Saha et al.
[2020] on whether there exists a polynomial-time algorithm with
$poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the
loss is linear up to an additive misspecification error, and our regret shows
near-optimal dependence on the magnitude of the error.



Title: Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic  Retinopathy Detection
Diabetic Retinopathy (DR) is a significant cause of blindness globally,
highlighting the urgent need for early detection and effective treatment.
Recent advancements in Machine Learning (ML) techniques have shown promise in
DR detection, but the availability of labeled data often limits their
performance. This research proposes a novel Semi-Supervised Graph Learning SSGL
algorithm tailored for DR detection, which capitalizes on the relationships
between labelled and unlabeled data to enhance accuracy. The work begins by
investigating data augmentation and preprocessing techniques to address the
challenges of image quality and feature variations. Techniques such as image
cropping, resizing, contrast adjustment, normalization, and data augmentation
are explored to optimize feature extraction and improve the overall quality of
retinal images. Moreover, apart from detection and diagnosis, this work delves
into applying ML algorithms for predicting the risk of developing DR or the
likelihood of disease progression. Personalized risk scores for individual
patients are generated using comprehensive patient data encompassing
demographic information, medical history, and retinal images. The proposed
Semi-Supervised Graph learning algorithm is rigorously evaluated on two
publicly available datasets and is benchmarked against existing methods.
Results indicate significant improvements in classification accuracy,
specificity, and sensitivity while demonstrating robustness against noise and
outlie rs.Notably, the proposed algorithm addresses the challenge of imbalanced
datasets, common in medical image analysis, further enhancing its practical
applicability.



Title: LeanContext: Cost-Efficient Domain-Specific Question Answering Using  LLMs
Question-answering (QA) is a significant application of Large Language Models
(LLMs), shaping chatbot capabilities across healthcare, education, and customer
service. However, widespread LLM integration presents a challenge for small
businesses due to the high expenses of LLM API usage. Costs rise rapidly when
domain-specific data (context) is used alongside queries for accurate
domain-specific LLM responses. One option is to summarize the context by using
LLMs and reduce the context. However, this can also filter out useful
information that is necessary to answer some domain-specific queries. In this
paper, we shift from human-oriented summarizers to AI model-friendly summaries.
Our approach, LeanContext, efficiently extracts $k$ key sentences from the
context that are closely aligned with the query. The choice of $k$ is neither
static nor random; we introduce a reinforcement learning technique that
dynamically determines $k$ based on the query and context. The rest of the less
important sentences are reduced using a free open source text reduction method.
We evaluate LeanContext against several recent query-aware and query-unaware
context reduction approaches on prominent datasets (arxiv papers and BBC news
articles). Despite cost reductions of $37.29\%$ to $67.81\%$, LeanContext's
ROUGE-1 score decreases only by $1.41\%$ to $2.65\%$ compared to a baseline
that retains the entire context (no summarization). Additionally, if free
pretrained LLM-based summarizers are used to reduce context (into human
consumable summaries), LeanContext can further modify the reduced context to
enhance the accuracy (ROUGE-1 score) by $13.22\%$ to $24.61\%$.



Title: Domain Generalization via Balancing Training Difficulty and Model  Capability
Domain generalization (DG) aims to learn domain-generalizable models from one
or multiple source domains that can perform well in unseen target domains.
Despite its recent progress, most existing work suffers from the misalignment
between the difficulty level of training samples and the capability of
contemporarily trained models, leading to over-fitting or under-fitting in the
trained generalization model. We design MoDify, a Momentum Difficulty framework
that tackles the misalignment by balancing the seesaw between the model's
capability and the samples' difficulties along the training process. MoDify
consists of two novel designs that collaborate to fight against the
misalignment while learning domain-generalizable models. The first is
MoDify-based Data Augmentation which exploits an RGB Shuffle technique to
generate difficulty-aware training samples on the fly. The second is
MoDify-based Network Optimization which dynamically schedules the training
samples for balanced and smooth learning with appropriate difficulty. Without
bells and whistles, a simple implementation of MoDify achieves superior
performance across multiple benchmarks. In addition, MoDify can complement
existing methods as a plug-in, and it is generic and can work for different
visual recognition tasks.



Title: Equitable-FL: Federated Learning with Sparsity for Resource-Constrained  Environment
In Federated Learning, model training is performed across multiple computing
devices, where only parameters are shared with a common central server without
exchanging their data instances. This strategy assumes abundance of resources
on individual clients and utilizes these resources to build a richer model as
user's models. However, when the assumption of the abundance of resources is
violated, learning may not be possible as some nodes may not be able to
participate in the process. In this paper, we propose a sparse form of
federated learning that performs well in a Resource Constrained Environment.
Our goal is to make learning possible, regardless of a node's space, computing,
or bandwidth scarcity. The method is based on the observation that model size
viz a viz available resources defines resource scarcity, which entails that
reduction of the number of parameters without affecting accuracy is key to
model training in a resource-constrained environment. In this work, the Lottery
Ticket Hypothesis approach is utilized to progressively sparsify models to
encourage nodes with resource scarcity to participate in collaborative
training. We validate Equitable-FL on the $MNIST$, $F-MNIST$, and $CIFAR-10$
benchmark datasets, as well as the $Brain-MRI$ data and the $PlantVillage$
datasets. Further, we examine the effect of sparsity on performance, model size
compaction, and speed-up for training. Results obtained from experiments
performed for training convolutional neural networks validate the efficacy of
Equitable-FL in heterogeneous resource-constrained learning environment.



Title: Regularly Truncated M-estimators for Learning with Noisy Labels
The sample selection approach is very popular in learning with noisy labels.
As deep networks learn pattern first, prior methods built on sample selection
share a similar training procedure: the small-loss examples can be regarded as
clean examples and used for helping generalization, while the large-loss
examples are treated as mislabeled ones and excluded from network parameter
updates. However, such a procedure is arguably debatable from two folds: (a) it
does not consider the bad influence of noisy labels in selected small-loss
examples; (b) it does not make good use of the discarded large-loss examples,
which may be clean or have meaningful information for generalization. In this
paper, we propose regularly truncated M-estimators (RTME) to address the above
two issues simultaneously. Specifically, RTME can alternately switch modes
between truncated M-estimators and original M-estimators. The former can
adaptively select small-losses examples without knowing the noise rate and
reduce the side-effects of noisy labels in them. The latter makes the possibly
clean examples but with large losses involved to help generalization.
Theoretically, we demonstrate that our strategies are label-noise-tolerant.
Empirically, comprehensive experimental results show that our method can
outperform multiple baselines and is robust to broad noise types and levels.



Title: Large Process Models: Business Process Management in the Age of  Generative AI
The continued success of Large Language Models (LLMs) and other generative
artificial intelligence approaches highlights the advantages that large
information corpora can have over rigidly defined symbolic models, but also
serves as a proof-point of the challenges that purely statistics-based
approaches have in terms of safety and trustworthiness. As a framework for
contextualizing the potential, as well as the limitations of LLMs and other
foundation model-based technologies, we propose the concept of a Large Process
Model (LPM) that combines the correlation power of LLMs with the analytical
precision and reliability of knowledge-based systems and automated reasoning
approaches. LPMs are envisioned to directly utilize the wealth of process
management experience that experts have accumulated, as well as process
performance data of organizations with diverse characteristics, e.g., regarding
size, region, or industry. In this vision, the proposed LPM would allow
organizations to receive context-specific (tailored) process and other business
models, analytical deep-dives, and improvement recommendations. As such, they
would allow to substantially decrease the time and effort required for business
transformation, while also allowing for deeper, more impactful, and more
actionable insights than previously possible. We argue that implementing an LPM
is feasible, but also highlight limitations and research challenges that need
to be solved to implement particular aspects of the LPM vision.



Title: A 3D explainability framework to uncover learning patterns and crucial  sub-regions in variable sulci recognition
Precisely identifying sulcal features in brain MRI is made challenging by the
variability of brain folding. This research introduces an innovative 3D
explainability frame-work that validates outputs from deep learning networks in
their ability to detect the paracingulate sulcus, an anatomical feature that
may or may not be present on the frontal medial surface of the human brain.
This study trained and tested two networks, amalgamating local explainability
techniques GradCam and SHAP with a dimensionality reduction method. The
explainability framework provided both localized and global explanations, along
with accuracy of classification results, revealing pertinent sub-regions
contributing to the decision process through a post-fusion transformation of
explanatory and statistical features. Leveraging the TOP-OSLO dataset of MRI
acquired from patients with schizophrenia, greater accuracies of paracingulate
sulcus detection (presence or absence) were found in the left compared to right
hemispheres with distinct, but extensive sub-regions contributing to each
classification outcome. The study also inadvertently highlighted the critical
role of an unbiased annotation protocol in maintaining network performance
fairness. Our proposed method not only offers automated, impartial annotations
of a variable sulcus but also provides insights into the broader anatomical
variations associated with its presence throughout the brain. The adoption of
this methodology holds promise for instigating further explorations and
inquiries in the field of neuroscience.



Title: Knowledge Graph Embeddings for Multi-Lingual Structured Representations  of Radiology Reports
The way we analyse clinical texts has undergone major changes over the last
years. The introduction of language models such as BERT led to adaptations for
the (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on
large databases of archived medical documents. While performing well in terms
of accuracy, both the lack of interpretability and limitations to transfer
across languages limit their use in clinical setting. We introduce a novel
light-weight graph-based embedding method specifically catering radiology
reports. It takes into account the structure and composition of the report,
while also connecting medical terms in the report through the multi-lingual
SNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers
the underlying relationships among clinical terms, achieving a representation
that is better understandable for clinicians and clinically more accurate,
without reliance on large pre-training datasets. We show the use of this
embedding on two tasks namely disease classification of X-ray reports and image
classification. For disease classification our model is competitive with its
BERT-based counterparts, while being magnitudes smaller in size and training
data requirements. For image classification, we show the effectiveness of the
graph embedding leveraging cross-modal knowledge transfer and show how this
method is usable across different languages.



Title: Deep supervised hashing for fast retrieval of radio image cubes
The shear number of sources that will be detected by next-generation radio
surveys will be astronomical, which will result in serendipitous discoveries.
Data-dependent deep hashing algorithms have been shown to be efficient at image
retrieval tasks in the fields of computer vision and multimedia. However, there
are limited applications of these methodologies in the field of astronomy. In
this work, we utilize deep hashing to rapidly search for similar images in a
large database. The experiment uses a balanced dataset of 2708 samples
consisting of four classes: Compact, FRI, FRII, and Bent. The performance of
the method was evaluated using the mean average precision (mAP) metric where a
precision of 88.5\% was achieved. The experimental results demonstrate the
capability to search and retrieve similar radio images efficiently and at
scale. The retrieval is based on the Hamming distance between the binary hash
of the query image and those of the reference images in the database.



Title: Content Prompting: Modeling Content Provider Dynamics to Improve User  Welfare in Recommender Ecosystems
Users derive value from a recommender system (RS) only to the extent that it
is able to surface content (or items) that meet their needs/preferences. While
RSs often have a comprehensive view of user preferences across the entire user
base, content providers, by contrast, generally have only a local view of the
preferences of users that have interacted with their content. This limits a
provider's ability to offer new content to best serve the broader population.
In this work, we tackle this information asymmetry with content prompting
policies. A content prompt is a hint or suggestion to a provider to make
available novel content for which the RS predicts unmet user demand. A
prompting policy is a sequence of such prompts that is responsive to the
dynamics of a provider's beliefs, skills and incentives. We aim to determine a
joint prompting policy that induces a set of providers to make content
available that optimizes user social welfare in equilibrium, while respecting
the incentives of the providers themselves. Our contributions include: (i) an
abstract model of the RS ecosystem, including content provider behaviors, that
supports such prompting; (ii) the design and theoretical analysis of sequential
prompting policies for individual providers; (iii) a mixed integer programming
formulation for optimal joint prompting using path planning in content space;
and (iv) simple, proof-of-concept experiments illustrating how such policies
improve ecosystem health and user welfare.



Title: Pressmatch: Automated journalist recommendation for media coverage with  Nearest Neighbor search
Slating a product for release often involves pitching journalists to run
stories on your press release. Good media coverage often ensures greater
product reach and drives audience engagement for those products. Hence,
ensuring that those releases are pitched to the right journalists with relevant
interests is crucial, since they receive several pitches daily. Keeping up with
journalist beats and curating a media contacts list is often a huge and
time-consuming task. This study proposes a model to automate and expedite the
process by recommending suitable journalists to run media coverage on the press
releases provided by the user.



Title: From Specific to Generic Learned Sorted Set Dictionaries: A  Theoretically Sound Paradigm Yelding Competitive Data Structural Boosters in  Practice
This research concerns Learned Data Structures, a recent area that has
emerged at the crossroad of Machine Learning and Classic Data Structures. It is
methodologically important and with a high practical impact. We focus on
Learned Indexes, i.e., Learned Sorted Set Dictionaries. The proposals available
so far are specific in the sense that they can boost, indeed impressively, the
time performance of Table Search Procedures with a sorted layout only, e.g.,
Binary Search. We propose a novel paradigm that, complementing known
specialized ones, can produce Learned versions of any Sorted Set Dictionary,
for instance, Balanced Binary Search Trees or Binary Search on layouts other
that sorted, i.e., Eytzinger. Theoretically, based on it, we obtain several
results of interest, such as (a) the first Learned Optimum Binary Search
Forest, with mean access time bounded by the Entropy of the probability
distribution of the accesses to the Dictionary; (b) the first Learned Sorted
Set Dictionary that, in the Dynamic Case and in an amortized analysis setting,
matches the same time bounds known for Classic Dictionaries. This latter under
widely accepted assumptions regarding the size of the Universe. The
experimental part, somewhat complex in terms of software development, clearly
indicates the nonobvious finding that the generalization we propose can yield
effective and competitive Learned Data Structural Booster, even with respect to
specific benchmark models.



Title: Bridge Diffusion Model: bridge non-English language-native text-to-image  diffusion model with English communities
Text-to-Image generation (TTI) technologies are advancing rapidly, especially
in the English language communities. However, English-native TTI models
inherently carry biases from English world centric training data, which creates
a dilemma for development of other language-native TTI models. One common
choice is fine-tuning the English-native TTI model with translated samples from
non-English communities. It falls short of fully addressing the model bias
problem. Alternatively, training non-English language native models from
scratch can effectively resolve the English world bias, but diverges from the
English TTI communities, thus not able to utilize the strides continuously
gaining in the English TTI communities any more. To build non-English language
native TTI model meanwhile keep compatability with the English TTI communities,
we propose a novel model structure referred as "Bridge Diffusion Model" (BDM).
The proposed BDM employs a backbone-branch network structure to learn the
non-English language semantics while keep the latent space compatible with the
English-native TTI backbone, in an end-to-end manner. The unique advantages of
the proposed BDM are that it's not only adept at generating images that
precisely depict non-English language semantics, but also compatible with
various English-native TTI plugins, such as different checkpoints, LoRA,
ControlNet, Dreambooth, and Textual Inversion, etc. Moreover, BDM can
concurrently generate content seamlessly combining both non-English native and
English-native semantics within a single image, fostering cultural interaction.
We verify our method by applying BDM to build a Chinese-native TTI model,
whereas the method is generic and applicable to any other language.



Title: Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip  Segmentation in Robotic Surgeries
Accurate segmentation of surgical instrument tip is an important task for
enabling downstream applications in robotic surgery, such as surgical skill
assessment, tool-tissue interaction and deformation modeling, as well as
surgical autonomy. However, this task is very challenging due to the small
sizes of surgical instrument tips, and significant variance of surgical scenes
across different procedures. Although much effort has been made on visual-based
methods, existing segmentation models still suffer from low robustness thus not
usable in practice. Fortunately, kinematics data from the robotic system can
provide reliable prior for instrument location, which is consistent regardless
of different surgery types. To make use of such multi-modal information, we
propose a novel visual-kinematics graph learning framework to accurately
segment the instrument tip given various surgical procedures. Specifically, a
graph learning framework is proposed to encode relational features of
instrument parts from both image and kinematics. Next, a cross-modal
contrastive loss is designed to incorporate robust geometric prior from
kinematics to image for tip segmentation. We have conducted experiments on a
private paired visual-kinematics dataset including multiple procedures, i.e.,
prostatectomy, total mesorectal excision, fundoplication and distal gastrectomy
on cadaver, and distal gastrectomy on porcine. The leave-one-procedure-out
cross validation demonstrated that our proposed multi-modal segmentation method
significantly outperformed current image-based state-of-the-art approaches,
exceeding averagely 11.2% on Dice.



Title: eDKM: An Efficient and Accurate Train-time Weight Clustering for Large  Language Models
Since Large Language Models or LLMs have demonstrated high-quality
performance on many complex language tasks, there is a great interest in
bringing these LLMs to mobile devices for faster responses and better privacy
protection. However, the size of LLMs (i.e., billions of parameters) requires
highly effective compression to fit into storage-limited devices. Among many
compression techniques, weight-clustering, a form of non-linear quantization,
is one of the leading candidates for LLM compression, and supported by modern
smartphones. Yet, its training overhead is prohibitively significant for LLM
fine-tuning. Especially, Differentiable KMeans Clustering, or DKM, has shown
the state-of-the-art trade-off between compression ratio and accuracy
regression, but its large memory complexity makes it nearly impossible to apply
to train-time LLM compression. In this paper, we propose a memory-efficient DKM
implementation, eDKM powered by novel techniques to reduce the memory footprint
of DKM by orders of magnitudes. For a given tensor to be saved on CPU for the
backward pass of DKM, we compressed the tensor by applying uniquification and
sharding after checking if there is no duplicated tensor previously copied to
CPU. Our experimental results demonstrate that \prjname can fine-tune and
compress a pretrained LLaMA 7B model from 12.6 GB to 2.5 GB (3bit/weight) with
the Alpaca dataset by reducing the train-time memory footprint of a decoder
layer by 130$\times$, while delivering good accuracy on broader LLM benchmarks
(i.e., 77.7\% for PIQA, 66.1\% for Winograde, and so on).



Title: Compositional Diffusion-Based Continuous Constraint Solvers
This paper introduces an approach for learning to solve continuous constraint
satisfaction problems (CCSP) in robotic reasoning and planning. Previous
methods primarily rely on hand-engineering or learning generators for specific
constraint types and then rejecting the value assignments when other
constraints are violated. By contrast, our model, the compositional diffusion
continuous constraint solver (Diffusion-CCSP) derives global solutions to CCSPs
by representing them as factor graphs and combining the energies of diffusion
models trained to sample for individual constraint types. Diffusion-CCSP
exhibits strong generalization to novel combinations of known constraints, and
it can be integrated into a task and motion planner to devise long-horizon
plans that include actions with both discrete and continuous parameters.
Project site: https://diffusion-ccsp.github.io/



Title: Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon  Manipulation
Many real-world manipulation tasks consist of a series of subtasks that are
significantly different from one another. Such long-horizon, complex tasks
highlight the potential of dexterous hands, which possess adaptability and
versatility, capable of seamlessly transitioning between different modes of
functionality without the need for re-grasping or external tools. However, the
challenges arise due to the high-dimensional action space of dexterous hand and
complex compositional dynamics of the long-horizon tasks. We present Sequential
Dexterity, a general system based on reinforcement learning (RL) that chains
multiple dexterous policies for achieving long-horizon task goals. The core of
the system is a transition feasibility function that progressively finetunes
the sub-policies for enhancing chaining success rate, while also enables
autonomous policy-switching for recovery from failures and bypassing redundant
stages. Despite being trained only in simulation with a few task objects, our
system demonstrates generalization capability to novel object shapes and is
able to zero-shot transfer to a real-world robot equipped with a dexterous
hand. More details and video results could be found at
https://sequential-dexterity.github.io



Title: Mitigating Motion Blur for Robust 3D Baseball Player Pose Modeling for  Pitch Analysis
Using videos to analyze pitchers in baseball can play a vital role in
strategizing and injury prevention. Computer vision-based pose analysis offers
a time-efficient and cost-effective approach. However, the use of accessible
broadcast videos, with a 30fps framerate, often results in partial body motion
blur during fast actions, limiting the performance of existing pose keypoint
estimation models. Previous works have primarily relied on fixed backgrounds,
assuming minimal motion differences between frames, or utilized multiview data
to address this problem. To this end, we propose a synthetic data augmentation
pipeline to enhance the model's capability to deal with the pitcher's blurry
actions. In addition, we leverage in-the-wild videos to make our model robust
under different real-world conditions and camera positions. By carefully
optimizing the augmentation parameters, we observed a notable reduction in the
loss by 54.2% and 36.2% on the test dataset for 2D and 3D pose estimation
respectively. By applying our approach to existing state-of-the-art pose
estimators, we demonstrate an average improvement of 29.2%. The findings
highlight the effectiveness of our method in mitigating the challenges posed by
motion blur, thereby enhancing the overall quality of pose estimation.



Title: Explainability for Large Language Models: A Survey
Large language models (LLMs) have demonstrated impressive capabilities in
natural language processing. However, their internal mechanisms are still
unclear and this lack of transparency poses unwanted risks for downstream
applications. Therefore, understanding and explaining these models is crucial
for elucidating their behaviors, limitations, and social impacts. In this
paper, we introduce a taxonomy of explainability techniques and provide a
structured overview of methods for explaining Transformer-based language
models. We categorize techniques based on the training paradigms of LLMs:
traditional fine-tuning-based paradigm and prompting-based paradigm. For each
paradigm, we summarize the goals and dominant approaches for generating local
explanations of individual predictions and global explanations of overall model
knowledge. We also discuss metrics for evaluating generated explanations, and
discuss how explanations can be leveraged to debug models and improve
performance. Lastly, we examine key challenges and emerging opportunities for
explanation techniques in the era of LLMs in comparison to conventional machine
learning models.



Title: Deep Deformable Models: Learning 3D Shape Abstractions with Part  Consistency
The task of shape abstraction with semantic part consistency is challenging
due to the complex geometries of natural objects. Recent methods learn to
represent an object shape using a set of simple primitives to fit the target.
\textcolor{black}{However, in these methods, the primitives used do not always
correspond to real parts or lack geometric flexibility for semantic
interpretation.} In this paper, we investigate salient and efficient primitive
descriptors for accurate shape abstractions, and propose \textit{Deep
Deformable Models (DDMs)}. DDM employs global deformations and diffeomorphic
local deformations. These properties enable DDM to abstract complex object
shapes with significantly fewer primitives that offer broader geometry coverage
and finer details. DDM is also capable of learning part-level semantic
correspondences due to the differentiable and invertible properties of our
primitive deformation. Moreover, DDM learning formulation is based on dynamic
and kinematic modeling, which enables joint regularization of each
sub-transformation during primitive fitting. Extensive experiments on
\textit{ShapeNet} demonstrate that DDM outperforms the state-of-the-art in
terms of reconstruction and part consistency by a notable margin.



Title: Integration of Vision-based Object Detection and Grasping for  Articulated Manipulator in Lunar Conditions
The integration of vision-based frameworks to achieve lunar robot
applications faces numerous challenges such as terrain configuration or extreme
lighting conditions. This paper presents a generic task pipeline using object
detection, instance segmentation and grasp detection, that can be used for
various applications by using the results of these vision-based systems in a
different way. We achieve a rock stacking task on a non-flat surface in
difficult lighting conditions with a very good success rate of 92%. Eventually,
we present an experiment to assemble 3D printed robot components to initiate
more complex tasks in the future.



Title: AB2CD: AI for Building Climate Damage Classification and Detection
We explore the implementation of deep learning techniques for precise
building damage assessment in the context of natural hazards, utilizing remote
sensing data. The xBD dataset, comprising diverse disaster events from across
the globe, serves as the primary focus, facilitating the evaluation of deep
learning models. We tackle the challenges of generalization to novel disasters
and regions while accounting for the influence of low-quality and noisy labels
inherent in natural hazard data. Furthermore, our investigation quantitatively
establishes that the minimum satellite imagery resolution essential for
effective building damage detection is 3 meters and below 1 meter for
classification using symmetric and asymmetric resolution perturbation analyses.
To achieve robust and accurate evaluations of building damage detection and
classification, we evaluated different deep learning models with residual,
squeeze and excitation, and dual path network backbones, as well as ensemble
techniques. Overall, the U-Net Siamese network ensemble with F-1 score of 0.812
performed the best against the xView2 challenge benchmark. Additionally, we
evaluate a Universal model trained on all hazards against a flood expert model
and investigate generalization gaps across events, and out of distribution from
field data in the Ahr Valley. Our research findings showcase the potential and
limitations of advanced AI solutions in enhancing the impact assessment of
climate change-induced extreme weather events, such as floods and hurricanes.
These insights have implications for disaster impact assessment in the face of
escalating climate challenges.



Title: Separable Hamiltonian Neural Networks
The modelling of dynamical systems from discrete observations is a challenge
faced by modern scientific and engineering data systems. Hamiltonian systems
are one such fundamental and ubiquitous class of dynamical systems. Hamiltonian
neural networks are state-of-the-art models that unsupervised-ly regress the
Hamiltonian of a dynamical system from discrete observations of its vector
field under the learning bias of Hamilton's equations. Yet Hamiltonian dynamics
are often complicated, especially in higher dimensions where the state space of
the Hamiltonian system is large relative to the number of samples. A recently
discovered remedy to alleviate the complexity between state variables in the
state space is to leverage the additive separability of the Hamiltonian system
and embed that additive separability into the Hamiltonian neural network.
Following the nomenclature of physics-informed machine learning, we propose
three separable Hamiltonian neural networks. These models embed additive
separability within Hamiltonian neural networks. The first model uses additive
separability to quadratically scale the amount of data for training Hamiltonian
neural networks. The second model embeds additive separability within the loss
function of the Hamiltonian neural network. The third model embeds additive
separability through the architecture of the Hamiltonian neural network using
conjoined multilayer perceptions. We empirically compare the three models
against state-of-the-art Hamiltonian neural networks, and demonstrate that the
separable Hamiltonian neural networks, which alleviate complexity between the
state variables, are more effective at regressing the Hamiltonian and its
vector field.



Title: Multidomain transformer-based deep learning for early detection of  network intrusion
Timely response of Network Intrusion Detection Systems (NIDS) is constrained
by the flow generation process which requires accumulation of network packets.
This paper introduces Multivariate Time Series (MTS) early detection into NIDS
to identify malicious flows prior to their arrival at target systems. With this
in mind, we first propose a novel feature extractor, Time Series Network Flow
Meter (TS-NFM), that represents network flow as MTS with explainable features,
and a new benchmark dataset is created using TS-NFM and the meta-data of
CICIDS2017, called SCVIC-TS-2022. Additionally, a new deep learning-based early
detection model called Multi-Domain Transformer (MDT) is proposed, which
incorporates the frequency domain into Transformer. This work further proposes
a Multi-Domain Multi-Head Attention (MD-MHA) mechanism to improve the ability
of MDT to extract better features. Based on the experimental results, the
proposed methodology improves the earliness of the conventional NIDS (i.e.,
percentage of packets that are used for classification) by 5x10^4 times and
duration-based earliness (i.e., percentage of duration of the classified
packets of a flow) by a factor of 60, resulting in a 84.1% macro F1 score (31%
higher than Transformer) on SCVIC-TS-2022. Additionally, the proposed MDT
outperforms the state-of-the-art early detection methods by 5% and 6% on ECG
and Wafer datasets, respectively.



Title: UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with  Geometric Topology Guidance
Object detection has long been a topic of high interest in computer vision
literature. Motivated by the fact that annotating data for the multi-object
tracking (MOT) problem is immensely expensive, recent studies have turned their
attention to the unsupervised learning setting. In this paper, we push forward
the state-of-the-art performance of unsupervised MOT methods by proposing
UnsMOT, a novel framework that explicitly combines the appearance and motion
features of objects with geometric information to provide more accurate
tracking. Specifically, we first extract the appearance and motion features
using CNN and RNN models, respectively. Then, we construct a graph of objects
based on their relative distances in a frame, which is fed into a GNN model
together with CNN features to output geometric embedding of objects optimized
using an unsupervised loss function. Finally, associations between objects are
found by matching not only similar extracted features but also geometric
embedding of detections and tracklets. Experimental results show remarkable
performance in terms of HOTA, IDF1, and MOTA metrics in comparison with
state-of-the-art methods.



Title: Stabilize to Act: Learning to Coordinate for Bimanual Manipulation
Key to rich, dexterous manipulation in the real world is the ability to
coordinate control across two hands. However, while the promise afforded by
bimanual robotic systems is immense, constructing control policies for dual arm
autonomous systems brings inherent difficulties. One such difficulty is the
high-dimensionality of the bimanual action space, which adds complexity to both
model-based and data-driven methods. We counteract this challenge by drawing
inspiration from humans to propose a novel role assignment framework: a
stabilizing arm holds an object in place to simplify the environment while an
acting arm executes the task. We instantiate this framework with BimanUal
Dexterity from Stabilization (BUDS), which uses a learned restabilizing
classifier to alternate between updating a learned stabilization position to
keep the environment unchanged, and accomplishing the task with an acting
policy learned from demonstrations. We evaluate BUDS on four bimanual tasks of
varying complexities on real-world robots, such as zipping jackets and cutting
vegetables. Given only 20 demonstrations, BUDS achieves 76.9% task success
across our task suite, and generalizes to out-of-distribution objects within a
class with a 52.7% success rate. BUDS is 56.0% more successful than an
unstructured baseline that instead learns a BC stabilizing policy due to the
precision required of these complex tasks. Supplementary material and videos
can be found at https://sites.google.com/view/stabilizetoact .



Title: M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive  Learning
Inspired by the successful application of contrastive learning on graphs,
researchers attempt to impose graph contrastive learning approaches on
heterogeneous information networks. Orthogonal to homogeneous graphs, the types
of nodes and edges in heterogeneous graphs are diverse so that specialized
graph contrastive learning methods are required. Most existing methods for
heterogeneous graph contrastive learning are implemented by transforming
heterogeneous graphs into homogeneous graphs, which may lead to ramifications
that the valuable information carried by non-target nodes is undermined thereby
exacerbating the performance of contrastive learning models. Additionally,
current heterogeneous graph contrastive learning methods are mainly based on
initial meta-paths given by the dataset, yet according to our deep-going
exploration, we derive empirical conclusions: only initial meta-paths cannot
contain sufficiently discriminative information; and various types of
meta-paths can effectively promote the performance of heterogeneous graph
contrastive learning methods. To this end, we propose a new multi-scale
meta-path integrated heterogeneous graph contrastive learning (M2HGCL) model,
which discards the conventional heterogeneity-homogeneity transformation and
performs the graph contrastive learning in a joint manner. Specifically, we
expand the meta-paths and jointly aggregate the direct neighbor information,
the initial meta-path neighbor information and the expanded meta-path neighbor
information to sufficiently capture discriminative information. A specific
positive sampling strategy is further imposed to remedy the intrinsic
deficiency of contrastive learning, i.e., the hard negative sample sampling
issue. Through extensive experiments on three real-world datasets, we
demonstrate that M2HGCL outperforms the current state-of-the-art baseline
models.



Title: MedChatZH: a Better Medical Adviser Learns from Better Instructions
Generative large language models (LLMs) have shown great success in various
applications, including question-answering (QA) and dialogue systems. However,
in specialized domains like traditional Chinese medical QA, these models may
perform unsatisfactorily without fine-tuning on domain-specific datasets. To
address this, we introduce MedChatZH, a dialogue model designed specifically
for traditional Chinese medical QA. Our model is pre-trained on Chinese
traditional medical books and fine-tuned with a carefully curated medical
instruction dataset. It outperforms several solid baselines on a real-world
medical dialogue dataset. We release our model, code, and dataset on
https://github.com/tyang816/MedChatZH to facilitate further research in the
domain of traditional Chinese medicine and LLMs.



Title: Financial Fraud Detection using Quantum Graph Neural Networks
Financial fraud detection is essential for preventing significant financial
losses and maintaining the reputation of financial institutions. However,
conventional methods of detecting financial fraud have limited effectiveness,
necessitating the need for new approaches to improve detection rates. In this
paper, we propose a novel approach for detecting financial fraud using Quantum
Graph Neural Networks (QGNNs). QGNNs are a type of neural network that can
process graph-structured data and leverage the power of Quantum Computing (QC)
to perform computations more efficiently than classical neural networks. Our
approach uses Variational Quantum Circuits (VQC) to enhance the performance of
the QGNN. In order to evaluate the efficiency of our proposed method, we
compared the performance of QGNNs to Classical Graph Neural Networks using a
real-world financial fraud detection dataset. The results of our experiments
showed that QGNNs achieved an AUC of $0.85$, which outperformed classical GNNs.
Our research highlights the potential of QGNNs and suggests that QGNNs are a
promising new approach for improving financial fraud detection.



Title: Interpretable Sequence Clustering
Categorical sequence clustering plays a crucial role in various fields, but
the lack of interpretability in cluster assignments poses significant
challenges. Sequences inherently lack explicit features, and existing sequence
clustering algorithms heavily rely on complex representations, making it
difficult to explain their results. To address this issue, we propose a method
called Interpretable Sequence Clustering Tree (ISCT), which combines sequential
patterns with a concise and interpretable tree structure. ISCT leverages k-1
patterns to generate k leaf nodes, corresponding to k clusters, which provides
an intuitive explanation on how each cluster is formed. More precisely, ISCT
first projects sequences into random subspaces and then utilizes the k-means
algorithm to obtain high-quality initial cluster assignments. Subsequently, it
constructs a pattern-based decision tree using a boosting-based construction
strategy in which sequences are re-projected and re-clustered at each node
before mining the top-1 discriminative splitting pattern. Experimental results
on 14 real-world data sets demonstrate that our proposed method provides an
interpretable tree structure while delivering fast and accurate cluster
assignments.



Title: FedFwd: Federated Learning without Backpropagation
In federated learning (FL), clients with limited resources can disrupt the
training efficiency. A potential solution to this problem is to leverage a new
learning procedure that does not rely on backpropagation (BP). We present a
novel approach to FL called FedFwd that employs a recent BP-free method by
Hinton (2022), namely the Forward Forward algorithm, in the local training
process. FedFwd can reduce a significant amount of computations for updating
parameters by performing layer-wise local updates, and therefore, there is no
need to store all intermediate activation values during training. We conduct
various experiments to evaluate FedFwd on standard datasets including MNIST and
CIFAR-10, and show that it works competitively to other BP-dependent FL
methods.



Title: Large Language Models for Generative Recommendation: A Survey and  Visionary Discussions
Recent years have witnessed the wide adoption of large language models (LLM)
in different fields, especially natural language processing and computer
vision. Such a trend can also be observed in recommender systems (RS). However,
most of related work treat LLM as a component of the conventional
recommendation pipeline (e.g., as a feature extractor) which may not be able to
fully leverage the generative power of LLM. Instead of separating the
recommendation process into multiple stages such as score computation and
re-ranking, this process can be simplified to one stage with LLM: directly
generating recommendations from the complete pool of items. This survey reviews
the progress, methods and future directions of LLM-based generative
recommendation by examining three questions: 1) What generative recommendation
is, 2) Why RS should advance to generative recommendation, and 3) How to
implement LLM-based generative recommendation for various RS tasks. We hope
that the survey can provide the context and guidance needed to explore this
interesting and emerging topic.



Title: Spatial-temporal Vehicle Re-identification
Vehicle re-identification (ReID) in a large-scale camera network is important
in public safety, traffic control, and security. However, due to the appearance
ambiguities of vehicle, the previous appearance-based ReID methods often fail
to track vehicle across multiple cameras. To overcome the challenge, we propose
a spatial-temporal vehicle ReID framework that estimates reliable camera
network topology based on the adaptive Parzen window method and optimally
combines the appearance and spatial-temporal similarities through the fusion
network. Based on the proposed methods, we performed superior performance on
the public dataset (VeRi776) by 99.64% of rank-1 accuracy. The experimental
results support that utilizing spatial and temporal information for ReID can
leverage the accuracy of appearance-based methods and effectively deal with
appearance ambiguities.



Title: End-to-End Learning on Multimodal Knowledge Graphs
Knowledge graphs enable data scientists to learn end-to-end on heterogeneous
knowledge. However, most end-to-end models solely learn from the relational
information encoded in graphs' structure: raw values, encoded as literal nodes,
are either omitted completely or treated as regular nodes without consideration
for their values. In either case we lose potentially relevant information which
could have otherwise been exploited by our learning methods. We propose a
multimodal message passing network which not only learns end-to-end from the
structure of graphs, but also from their possibly divers set of multimodal node
features. Our model uses dedicated (neural) encoders to naturally learn
embeddings for node features belonging to five different types of modalities,
including numbers, texts, dates, images and geometries, which are projected
into a joint representation space together with their relational information.
We implement and demonstrate our model on node classification and link
prediction for artificial and real-worlds datasets, and evaluate the effect
that each modality has on the overall performance in an inverse ablation study.
Our results indicate that end-to-end multimodal learning from any arbitrary
knowledge graph is indeed possible, and that including multimodal information
can significantly affect performance, but that much depends on the
characteristics of the data.



Title: FusionAI: Decentralized Training and Deploying LLMs with Massive  Consumer-Level GPUs
The rapid growth of memory and computation requirements of large language
models (LLMs) has outpaced the development of hardware, hindering people who
lack large-scale high-end GPUs from training or deploying LLMs. However,
consumer-level GPUs, which constitute a larger market share, are typically
overlooked in LLM due to their weaker computing performance, smaller storage
capacity, and lower communication bandwidth. Additionally, users may have
privacy concerns when interacting with remote LLMs. In this paper, we envision
a decentralized system unlocking the potential vast untapped consumer-level
GPUs in pre-training, inference and fine-tuning of LLMs with privacy
protection. However, this system faces critical challenges, including limited
CPU and GPU memory, low network bandwidth, the variability of peer and device
heterogeneity. To address these challenges, our system design incorporates: 1)
a broker with backup pool to implement dynamic join and quit of computing
providers; 2) task scheduling with hardware performance to improve system
efficiency; 3) abstracting ML procedures into directed acyclic graphs (DAGs) to
achieve model and task universality; 4) abstracting intermediate represention
and execution planes to ensure compatibility of various devices and deep
learning (DL) frameworks. Our performance analysis demonstrates that 50 RTX
3080 GPUs can achieve throughputs comparable to those of 4 H100 GPUs, which are
significantly more expensive.



Title: Cognition-Mode Aware Variational Representation Learning Framework for  Knowledge Tracing
The Knowledge Tracing (KT) task plays a crucial role in personalized
learning, and its purpose is to predict student responses based on their
historical practice behavior sequence. However, the KT task suffers from data
sparsity, which makes it challenging to learn robust representations for
students with few practice records and increases the risk of model overfitting.
Therefore, in this paper, we propose a Cognition-Mode Aware Variational
Representation Learning Framework (CMVF) that can be directly applied to
existing KT methods. Our framework uses a probabilistic model to generate a
distribution for each student, accounting for uncertainty in those with limited
practice records, and estimate the student's distribution via variational
inference (VI). In addition, we also introduce a cognition-mode aware
multinomial distribution as prior knowledge that constrains the posterior
student distributions learning, so as to ensure that students with similar
cognition modes have similar distributions, avoiding overwhelming
personalization for students with few practice records. At last, extensive
experimental results confirm that CMVF can effectively aid existing KT methods
in learning more robust student representations. Our code is available at
https://github.com/zmy-9/CMVF.



Title: Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for  Recommendation Systems
Modern neural collaborative filtering techniques are critical to the success
of e-commerce, social media, and content-sharing platforms. However, despite
technical advances -- for every new application domain, we need to train an NCF
model from scratch. In contrast, pre-trained vision and language models are
routinely applied to diverse applications directly (zero-shot) or with limited
fine-tuning. Inspired by the impact of pre-trained models, we explore the
possibility of pre-trained recommender models that support building recommender
systems in new domains, with minimal or no retraining, without the use of any
auxiliary user or item information. Zero-shot recommendation without auxiliary
information is challenging because we cannot form associations between users
and items across datasets when there are no overlapping users or items. Our
fundamental insight is that the statistical characteristics of the user-item
interaction matrix are universally available across different domains and
datasets. Thus, we use the statistical characteristics of the user-item
interaction matrix to identify dataset-independent representations for users
and items. We show how to learn universal (i.e., supporting zero-shot
adaptation without user or item auxiliary information) representations for
nodes and edges from the bipartite user-item interaction graph. We learn
representations by exploiting the statistical properties of the interaction
data, including user and item marginals, and the size and density distributions
of their clusters.



Title: LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection
The increasing volume of log data produced by software-intensive systems
makes it impractical to analyze them manually. Many deep learning-based methods
have been proposed for log-based anomaly detection. These methods face several
challenges such as high-dimensional and noisy log data, class imbalance,
generalization, and model interpretability. Recently, ChatGPT has shown
promising results in various domains. However, there is still a lack of study
on the application of ChatGPT for log-based anomaly detection. In this work, we
proposed LogGPT, a log-based anomaly detection framework based on ChatGPT. By
leveraging the ChatGPT's language interpretation capabilities, LogGPT aims to
explore the transferability of knowledge from large-scale corpora to log-based
anomaly detection. We conduct experiments to evaluate the performance of LogGPT
and compare it with three deep learning-based methods on BGL and Spirit
datasets. LogGPT shows promising results and has good interpretability. This
study provides preliminary insights into prompt-based models, such as ChatGPT,
for the log-based anomaly detection task.



Title: A Visual Interpretation-Based Self-Improved Classification System Using  Virtual Adversarial Training
The successful application of large pre-trained models such as BERT in
natural language processing has attracted more attention from researchers.
Since the BERT typically acts as an end-to-end black box, classification
systems based on it usually have difficulty in interpretation and low
robustness. This paper proposes a visual interpretation-based self-improving
classification model with a combination of virtual adversarial training (VAT)
and BERT models to address the above problems. Specifically, a fine-tuned BERT
model is used as a classifier to classify the sentiment of the text. Then, the
predicted sentiment classification labels are used as part of the input of
another BERT for spam classification via a semi-supervised training manner
using VAT. Additionally, visualization techniques, including visualizing the
importance of words and normalizing the attention head matrix, are employed to
analyze the relevance of each component to classification accuracy. Moreover,
brand-new features will be found in the visual analysis, and classification
performance will be improved. Experimental results on Twitter's tweet dataset
demonstrate the effectiveness of the proposed model on the classification task.
Furthermore, the ablation study results illustrate the effect of different
components of the proposed model on the classification results.



Title: Physics-inspired Neural Networks for Parameter Learning of Adaptive  Cruise Control Systems
This paper proposes and develops a physics-inspired neural network (PiNN) for
learning the parameters of commercially implemented adaptive cruise control
(ACC) systems in automotive industry. To emulate the core functionality of
stock ACC systems, which have proprietary control logic and undisclosed
parameters, the constant time-headway policy (CTHP) is adopted. Leveraging the
multi-layer artificial neural networks as universal approximators, the
developed PiNN serves as a surrogate model for the longitudinal dynamics of
ACC-engaged vehicles, efficiently learning the unknown parameters of the CTHP.
The ability of the PiNN to infer the unknown ACC parameters is meticulous
evaluated using both synthetic and high-fidelity empirical data of space-gap
and relative velocity involving ACC-engaged vehicles in platoon formation. The
results have demonstrated the superior predictive ability of the proposed PiNN
in learning the unknown design parameters of stock ACC systems from different
car manufacturers. The set of ACC model parameters obtained from the PiNN
revealed that the stock ACC systems of the considered vehicles in three
experimental campaigns are neither $L_2$ nor $L_\infty$ string stable.



Title: Siren's Song in the AI Ocean: A Survey on Hallucination in Large  Language Models
While large language models (LLMs) have demonstrated remarkable capabilities
across a range of downstream tasks, a significant concern revolves around their
propensity to exhibit hallucinations: LLMs occasionally generate content that
diverges from the user input, contradicts previously generated context, or
misaligns with established world knowledge. This phenomenon poses a substantial
challenge to the reliability of LLMs in real-world scenarios. In this paper, we
survey recent efforts on the detection, explanation, and mitigation of
hallucination, with an emphasis on the unique challenges posed by LLMs. We
present taxonomies of the LLM hallucination phenomena and evaluation
benchmarks, analyze existing approaches aiming at mitigating LLM hallucination,
and discuss potential directions for future research.



Title: Saturn: An Optimized Data System for Large Model Deep Learning Workloads
Large language models such as GPT-3 & ChatGPT have transformed deep learning
(DL), powering applications that have captured the public's imagination. These
models are rapidly being adopted across domains for analytics on various
modalities, often by finetuning pre-trained base models. Such models need
multiple GPUs due to both their size and computational load, driving the
development of a bevy of "model parallelism" techniques & tools. Navigating
such parallelism choices, however, is a new burden for end users of DL such as
data scientists, domain scientists, etc. who may lack the necessary systems
knowhow. The need for model selection, which leads to many models to train due
to hyper-parameter tuning or layer-wise finetuning, compounds the situation
with two more burdens: resource apportioning and scheduling. In this work, we
tackle these three burdens for DL users in a unified manner by formalizing them
as a joint problem that we call SPASE: Select a Parallelism, Allocate
resources, and SchedulE. We propose a new information system architecture to
tackle the SPASE problem holistically, representing a key step toward enabling
wider adoption of large DL models. We devise an extensible template for
existing parallelism schemes and combine it with an automated empirical
profiler for runtime estimation. We then formulate SPASE as an MILP. We find that direct use of an MILP-solver is significantly more effective
than several baseline heuristics. We optimize the system runtime further with
an introspective scheduling approach. We implement all these techniques into a
new data system we call Saturn. Experiments with benchmark DL workloads show
that Saturn achieves 39-49% lower model selection runtimes than typical current
DL practice.



Title: Representations Matter: Embedding Modes of Large Language Models using  Dynamic Mode Decomposition
Existing large language models (LLMs) are known for generating "hallucinated"
content, namely a fabricated text of plausibly looking, yet unfounded, facts.
To identify when these hallucination scenarios occur, we examine the properties
of the generated text in the embedding space. Specifically, we draw inspiration
from the dynamic mode decomposition (DMD) tool in analyzing the pattern
evolution of text embeddings across sentences. We empirically demonstrate how
the spectrum of sentence embeddings over paragraphs is constantly low-rank for
the generated text, unlike that of the ground-truth text. Importantly, we find
that evaluation cases having LLM hallucinations correspond to ground-truth
embedding patterns with a higher number of modes being poorly approximated by
the few modes associated with LLM embedding patterns. In analogy to near-field
electromagnetic evanescent waves, the embedding DMD eigenmodes of the generated
text with hallucinations vanishes quickly across sentences as opposed to those
of the ground-truth text. This suggests that the hallucinations result from
both the generation techniques and the underlying representation.



Title: Learning-Aware Safety for Interactive Autonomy
One of the outstanding challenges for the widespread deployment of robotic
systems like autonomous vehicles is ensuring safe interaction with humans
without sacrificing efficiency. Existing safety analysis methods often neglect
the robot's ability to learn and adapt at runtime, leading to overly
conservative behavior. This paper proposes a new closed-loop paradigm for
synthesizing safe control policies that explicitly account for the system's
evolving uncertainty under possible future scenarios. The formulation reasons
jointly about the physical dynamics and the robot's learning algorithm, which
updates its internal belief over time. We leverage adversarial deep
reinforcement learning (RL) for scaling to high dimensions, enabling tractable
safety analysis even for implicit learning dynamics induced by state-of-the-art
prediction models. We demonstrate our framework's ability to work with both
Bayesian belief propagation and the implicit learning induced by a large
pre-trained neural trajectory predictor.



Title: COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action  Spotting using Transformers
We present COMEDIAN, a novel pipeline to initialize spatio-temporal
transformers for action spotting, which involves self-supervised learning and
knowledge distillation. Action spotting is a timestamp-level temporal action
detection task. Our pipeline consists of three steps, with two initialization
stages. First, we perform self-supervised initialization of a spatial
transformer using short videos as input. Additionally, we initialize a temporal
transformer that enhances the spatial transformer's outputs with global context
through knowledge distillation from a pre-computed feature bank aligned with
each short video segment. In the final step, we fine-tune the transformers to
the action spotting task. The experiments, conducted on the SoccerNet-v2
dataset, demonstrate state-of-the-art performance and validate the
effectiveness of COMEDIAN's pretraining paradigm. Our results highlight several
advantages of our pretraining pipeline, including improved performance and
faster convergence compared to non-pretrained models.



Title: Bayesian inference of composition-dependent phase diagrams
Phase diagrams serve as a highly informative tool for materials design,
encapsulating information about the phases that a material can manifest under
specific conditions. In this work, we develop a method in which Bayesian
inference is employed to combine thermodynamic data from molecular dynamics
(MD), melting point simulations, and phonon calculations, process these data,
and yield a temperature-concentration phase diagram. The employed Bayesian
framework yields us not only the free energies of different phases as functions
of temperature and concentration but also the uncertainties of these free
energies originating from statistical errors inherent to finite-length MD
trajectories. Furthermore, it extrapolates the results of the finite-atom
calculations to the infinite-atom limit and facilitates the choice of
temperature, chemical potentials, and the number of atoms conducting the next
simulation with which will be the most efficient in reducing the uncertainty of
the phase diagram. The developed algorithm was successfully tested on two
binary systems, Ge-Si and K-Na, in the full range of concentrations and
temperatures.



Title: Generative Social Choice
Traditionally, social choice theory has only been applicable to choices among
a few predetermined alternatives but not to more complex decisions such as
collectively selecting a textual statement. We introduce generative social
choice, a framework that combines the mathematical rigor of social choice
theory with large language models' capability to generate text and extrapolate
preferences. This framework divides the design of AI-augmented democratic
processes into two components: first, proving that the process satisfies
rigorous representation guarantees when given access to oracle queries; second,
empirically validating that these queries can be approximately implemented
using a large language model. We illustrate this framework by applying it to
the problem of generating a slate of statements that is representative of
opinions expressed as free-form text, for instance in an online deliberative
process.



Title: Partial Proof of a Conjecture with Implications for Spectral  Majorization
In this paper we report on new results relating to a conjecture regarding
properties of $n\times n$, $n\leq 6$, positive definite matrices. The
conjecture has been proven for $n\leq 4$ using computer-assisted sum of squares
(SoS) methods for proving polynomial nonnegativity. Based on these proven
cases, we report on the recent identification of a new family of matrices with
the property that their diagonals majorize their spectrum. We then present new
results showing that this family can extended via Kronecker composition to
$n>6$ while retaining the special majorization property. We conclude with
general considerations on the future of computer-assisted and AI-based proofs.



Title: ExMobileViT: Lightweight Classifier Extension for Mobile Vision  Transformer
The paper proposes an efficient structure for enhancing the performance of
mobile-friendly vision transformer with small computational overhead. The
vision transformer (ViT) is very attractive in that it reaches outperforming
results in image classification, compared to conventional convolutional neural
networks (CNNs). Due to its need of high computational resources,
MobileNet-based ViT models such as MobileViT-S have been developed. However,
their performance cannot reach the original ViT model. The proposed structure
relieves the above weakness by storing the information from early attention
stages and reusing it in the final classifier. This paper is motivated by the
idea that the data itself from early attention stages can have important
meaning for the final classification. In order to reuse the early information
in attention stages, the average pooling results of various scaled features
from early attention stages are used to expand channels in the fully-connected
layer of the final classifier. It is expected that the inductive bias
introduced by the averaged features can enhance the final performance. Because
the proposed structure only needs the average pooling of features from the
attention stages and channel expansions in the final classifier, its
computational and storage overheads are very small, keeping the benefits of
low-cost MobileNet-based ViT (MobileViT). Compared with the original MobileViTs
on the ImageNet dataset, the proposed ExMobileViT has noticeable accuracy
enhancements, having only about 5% additional parameters.



Title: Can I Trust Your Answer? Visually Grounded Video Question Answering
We study visually grounded VideoQA in response to the emerging trends of
utilizing pretraining techniques for video-language understanding.
Specifically, by forcing vision-language models (VLMs) to answer questions and
simultaneously provide visual evidence, we seek to ascertain the extent to
which the predictions of such techniques are genuinely anchored in relevant
video content, versus spurious correlations from language or irrelevant visual
context. Towards this, we construct NExT-GQA -- an extension of NExT-QA with
10.5$K$ temporal grounding (or location) labels tied to the original QA pairs.
With NExT-GQA, we scrutinize a variety of state-of-the-art VLMs. Through
post-hoc attention analysis, we find that these models are weak in
substantiating the answers despite their strong QA performance. This exposes a
severe limitation of these models in making reliable predictions. As a remedy,
we further explore and suggest a video grounding mechanism via Gaussian mask
optimization and cross-modal learning. Experiments with different backbones
demonstrate that this grounding mechanism improves both video grounding and QA.
Our dataset and code are released. With these efforts, we aim to push towards
the reliability of deploying VLMs in VQA systems.



Title: Learning for Interval Prediction of Electricity Demand: A Cluster-based  Bootstrapping Approach
Accurate predictions of electricity demands are necessary for managing
operations in a small aggregation load setting like a Microgrid. Due to low
aggregation, the electricity demands can be highly stochastic and point
estimates would lead to inflated errors. Interval estimation in this scenario,
would provide a range of values within which the future values might lie and
helps quantify the errors around the point estimates. This paper introduces a
residual bootstrap algorithm to generate interval estimates of day-ahead
electricity demand. A machine learning algorithm is used to obtain the point
estimates of electricity demand and respective residuals on the training set.
The obtained residuals are stored in memory and the memory is further
partitioned. Days with similar demand patterns are grouped in clusters using an
unsupervised learning algorithm and these clusters are used to partition the
memory. The point estimates for test day are used to find the closest cluster
of similar days and the residuals are bootstrapped from the chosen cluster.
This algorithm is evaluated on the real electricity demand data from EULR(End
Use Load Research) and is compared to other bootstrapping methods for varying
confidence intervals.



Title: UniSA: Unified Generative Framework for Sentiment Analysis
Sentiment analysis is a crucial task that aims to understand people's
emotional states and predict emotional categories based on multimodal
information. It consists of several subtasks, such as emotion recognition in
conversation (ERC), aspect-based sentiment analysis (ABSA), and multimodal
sentiment analysis (MSA). However, unifying all subtasks in sentiment analysis
presents numerous challenges, including modality alignment, unified
input/output forms, and dataset bias. To address these challenges, we propose a
Task-Specific Prompt method to jointly model subtasks and introduce a
multimodal generative framework called UniSA. Additionally, we organize the
benchmark datasets of main subtasks into a new Sentiment Analysis Evaluation
benchmark, SAEval. We design novel pre-training tasks and training methods to
enable the model to learn generic sentiment knowledge among subtasks to improve
the model's multimodal sentiment perception ability. Our experimental results
show that UniSA performs comparably to the state-of-the-art on all subtasks and
generalizes well to various subtasks in sentiment analysis.



Title: Self-driven Grounding: Large Language Model Agents with Automatical  Language-aligned Skill Learning
Large language models (LLMs) show their powerful automatic reasoning and
planning capability with a wealth of semantic knowledge about the human world.
However, the grounding problem still hinders the applications of LLMs in the
real-world environment. Existing studies try to fine-tune the LLM or utilize
pre-defined behavior APIs to bridge the LLMs and the environment, which not
only costs huge human efforts to customize for every single task but also
weakens the generality strengths of LLMs. To autonomously ground the LLM onto
the environment, we proposed the Self-Driven Grounding (SDG) framework to
automatically and progressively ground the LLM with self-driven skill learning.
SDG first employs the LLM to propose the hypothesis of sub-goals to achieve
tasks and then verify the feasibility of the hypothesis via interacting with
the underlying environment. Once verified, SDG can then learn generalized
skills with the guidance of these successfully grounded subgoals. These skills
can be further utilized to accomplish more complex tasks which fail to pass the
verification phase. Verified in the famous instruction following task
set-BabyAI, SDG achieves comparable performance in the most challenging tasks
compared with imitation learning methods that cost millions of demonstrations,
proving the effectiveness of learned skills and showing the feasibility and
efficiency of our framework.



Title: Refined Temporal Pyramidal Compression-and-Amplification Transformer for  3D Human Pose Estimation
Accurately estimating the 3D pose of humans in video sequences requires both
accuracy and a well-structured architecture. With the success of transformers,
we introduce the Refined Temporal Pyramidal Compression-and-Amplification
(RTPCA) transformer. Exploiting the temporal dimension, RTPCA extends
intra-block temporal modeling via its Temporal Pyramidal
Compression-and-Amplification (TPCA) structure and refines inter-block feature
interaction with a Cross-Layer Refinement (XLR) module. In particular, TPCA
block exploits a temporal pyramid paradigm, reinforcing key and value
representation capabilities and seamlessly extracting spatial semantics from
motion sequences. We stitch these TPCA blocks with XLR that promotes rich
semantic representation through continuous interaction of queries, keys, and
values. This strategy embodies early-stage information with current flows,
addressing typical deficits in detail and stability seen in other
transformer-based methods. We demonstrate the effectiveness of RTPCA by
achieving state-of-the-art results on Human3.6M, HumanEva-I, and MPI-INF-3DHP
benchmarks with minimal computational overhead. The source code is available at
https://github.com/hbing-l/RTPCA.



Title: ReOnto: A Neuro-Symbolic Approach for Biomedical Relation Extraction
Relation Extraction (RE) is the task of extracting semantic relationships
between entities in a sentence and aligning them to relations defined in a
vocabulary, which is generally in the form of a Knowledge Graph (KG) or an
ontology. Various approaches have been proposed so far to address this task.
However, applying these techniques to biomedical text often yields
unsatisfactory results because it is hard to infer relations directly from
sentences due to the nature of the biomedical relations. To address these
issues, we present a novel technique called ReOnto, that makes use of neuro
symbolic knowledge for the RE task. ReOnto employs a graph neural network to
acquire the sentence representation and leverages publicly accessible
ontologies as prior knowledge to identify the sentential relation between two
entities. The approach involves extracting the relation path between the two
entities from the ontology. We evaluate the effect of using symbolic knowledge
from ontologies with graph neural networks. Experimental results on two public
biomedical datasets, BioRel and ADE, show that our method outperforms all the
baselines (approximately by 3\%).



Title: Memory augment is All You Need for image restoration
Image restoration is a low-level vision task, most CNN methods are designed
as a black box, lacking transparency and internal aesthetics. Although some
methods combining traditional optimization algorithms with DNNs have been
proposed, they all have some limitations. In this paper, we propose a
three-granularity memory layer and contrast learning named MemoryNet,
specifically, dividing the samples into positive, negative, and actual three
samples for contrastive learning, where the memory layer is able to preserve
the deep features of the image and the contrastive learning converges the
learned features to balance. Experiments on Derain/Deshadow/Deblur task
demonstrate that these methods are effective in improving restoration
performance. In addition, this paper's model obtains significant PSNR, SSIM
gain on three datasets with different degradation types, which is a strong
proof that the recovered images are perceptually realistic. The source code of
MemoryNet can be obtained from https://github.com/zhangbaijin/MemoryNet



Title: LoRA-like Calibration for Multimodal Deception Detection using ATSFace  Data
Recently, deception detection on human videos is an eye-catching techniques
and can serve lots applications. AI model in this domain demonstrates the high
accuracy, but AI tends to be a non-interpretable black box. We introduce an
attention-aware neural network addressing challenges inherent in video data and
deception dynamics. This model, through its continuous assessment of visual,
audio, and text features, pinpoints deceptive cues. We employ a multimodal
fusion strategy that enhances accuracy; our approach yields a 92\% accuracy
rate on a real-life trial dataset. Most important of all, the model indicates
the attention focus in the videos, providing valuable insights on deception
cues. Hence, our method adeptly detects deceit and elucidates the underlying
process. We further enriched our study with an experiment involving students
answering questions either truthfully or deceitfully, resulting in a new
dataset of 309 video clips, named ATSFace. Using this, we also introduced a
calibration method, which is inspired by Low-Rank Adaptation (LoRA), to refine
individual-based deception detection accuracy.



Title: Metric Learning for Projections Bias of Generalized Zero-shot Learning
Generalized zero-shot learning models (GZSL) aim to recognize samples from
seen or unseen classes using only samples from seen classes as training data.
During inference, GZSL methods are often biased towards seen classes due to the
visibility of seen class samples during training. Most current GZSL methods try
to learn an accurate projection function (from visual space to semantic space)
to avoid bias and ensure the effectiveness of GZSL methods. However, during
inference, the computation of distance will be important when we classify the
projection of any sample into its nearest class since we may learn a biased
projection function in the model. In our work, we attempt to learn a
parameterized Mahalanobis distance within the framework of VAEGAN (Variational
Autoencoder \& Generative Adversarial Networks), where the weight matrix
depends on the network's output. In particular, we improved the network
structure of VAEGAN to leverage the discriminative models of two branches to
separately predict the seen samples and the unseen samples generated by this
seen one. We proposed a new loss function with two branches to help us learn
the optimized Mahalanobis distance representation. Comprehensive evaluation
benchmarks on four datasets demonstrate the superiority of our method over the
state-of-the-art counterparts. Our codes are available at
https://anonymous.4open.science/r/111hxr.



Title: Social Factors in P2P Energy Trading Using Hedonic Games
Lately, the energy communities have gained a lot of attention as they have
the potential to significantly contribute to the resilience and flexibility of
the energy system, facilitating widespread integration of intermittent
renewable energy sources. Within these communities the prosumers can engage in
peer-to-peer trading, fostering local collaborations and increasing awareness
about energy usage and flexible consumption. However, even under these
favorable conditions, prosumer engagement levels remain low, requiring trading
mechanisms that are aligned with their social values and expectations. In this
paper, we introduce an innovative hedonic game coordination and cooperation
model for P2P energy trading among prosumers which considers the social
relationships within an energy community to create energy coalitions and
facilitate energy transactions among them. We defined a heuristic that
optimizes the prosumers coalitions, considering their social and energy price
preferences and balancing the energy demand and supply within the community. We
integrated the proposed hedonic game model into a state-of-the-art
blockchain-based P2P energy flexibility market and evaluated its performance
within an energy community of prosumers. The evaluation results on a
blockchain-based P2P energy flexibility market show the effectiveness in
considering social factors when creating coalitions, increasing the total
amount of energy transacted in a market session by 5% compared with other game
theory-based solutions. Finally, it shows the importance of the social
dimensions of P2P energy transactions, the positive social dynamics in the
energy community increasing the amount of energy transacted by more than 10%
while contributing to a more balanced energy demand and supply within the
community.



Title: Interactive Graph Convolutional Filtering
Interactive Recommender Systems (IRS) have been increasingly used in various
domains, including personalized article recommendation, social media, and
online advertising. However, IRS faces significant challenges in providing
accurate recommendations under limited observations, especially in the context
of interactive collaborative filtering. These problems are exacerbated by the
cold start problem and data sparsity problem. Existing Multi-Armed Bandit
methods, despite their carefully designed exploration strategies, often
struggle to provide satisfactory results in the early stages due to the lack of
interaction data. Furthermore, these methods are computationally intractable
when applied to non-linear models, limiting their applicability. To address
these challenges, we propose a novel method, the Interactive Graph
Convolutional Filtering model. Our proposed method extends interactive
collaborative filtering into the graph model to enhance the performance of
collaborative filtering between users and items. We incorporate variational
inference techniques to overcome the computational hurdles posed by non-linear
models. Furthermore, we employ Bayesian meta-learning methods to effectively
address the cold-start problem and derive theoretical regret bounds for our
proposed method, ensuring a robust performance guarantee. Extensive
experimental results on three real-world datasets validate our method and
demonstrate its superiority over existing baselines.



Title: BadSQA: Stealthy Backdoor Attacks Using Presence Events as Triggers in  Non-Intrusive Speech Quality Assessment
Non-Intrusive speech quality assessment (NISQA) has gained significant
attention for predicting the mean opinion score (MOS) of speech without
requiring the reference speech. In practical NISQA scenarios, untrusted
third-party resources are often employed during deep neural network training to
reduce costs. However, it would introduce a potential security vulnerability as
specially designed untrusted resources can launch backdoor attacks against
NISQA systems. Existing backdoor attacks primarily focus on classification
tasks and are not directly applicable to NISQA which is a regression task. In
this paper, we propose a novel backdoor attack on NISQA tasks, leveraging
presence events as triggers to achieving highly stealthy attacks. To evaluate
the effectiveness of our proposed approach, we conducted experiments on four
benchmark datasets and employed two state-of-the-art NISQA models. The results
demonstrate that the proposed backdoor attack achieved an average attack
success rate of up to 99% with a poisoning rate of only 3%.



Title: Memory Efficient Optimizers with 4-bit States
Optimizer states are a major source of memory consumption for training neural
networks, limiting the maximum trainable model within given memory budget.
Compressing the optimizer states from 32-bit floating points to lower bitwidth
is promising to reduce the training memory footprint, while the current lowest
achievable bitwidth is 8-bit. In this work, we push optimizer states bitwidth
down to 4-bit through a detailed empirical analysis of first and second order
momentums. Specifically, we find that momentums have complicated outlier
patterns, that current block-wise quantization cannot accurately approximate.
We use a smaller block size and propose to utilize both row-wise and
column-wise information for better quantization. We further identify a zero
point problem of quantizing the second-order momentum, and solve this problem
with a linear quantizer that excludes the zero point. Our 4-bit optimizer is
evaluated on a wide variety of benchmarks including natural language
understanding, machine translation, image classification, and instruction
tuning. On all the tasks our optimizers can achieve comparable accuracy with
their full-precision counterparts, while enjoying better memory efficiency.



Title: Neural Vector Fields: Generalizing Distance Vector Fields by Codebooks  and Zero-Curl Regularization
Recent neural networks based surface reconstruction can be roughly divided
into two categories, one warping templates explicitly and the other
representing 3D surfaces implicitly. To enjoy the advantages of both, we
propose a novel 3D representation, Neural Vector Fields (NVF), which adopts the
explicit learning process to manipulate meshes and implicit unsigned distance
function (UDF) representation to break the barriers in resolution and topology.
This is achieved by directly predicting the displacements from surface queries
and modeling shapes as Vector Fields, rather than relying on network
differentiation to obtain direction fields as most existing UDF-based methods
do. In this way, our approach is capable of encoding both the distance and the
direction fields so that the calculation of direction fields is
differentiation-free, circumventing the non-trivial surface extraction step.
Furthermore, building upon NVFs, we propose to incorporate two types of shape
codebooks, \ie, NVFs (Lite or Ultra), to promote cross-category reconstruction
through encoding cross-object priors. Moreover, we propose a new regularization
based on analyzing the zero-curl property of NVFs, and implement this through
the fully differentiable framework of our NVF (ultra). We evaluate both NVFs on
four surface reconstruction scenarios, including watertight vs non-watertight
shapes, category-agnostic reconstruction vs category-unseen reconstruction,
category-specific, and cross-domain reconstruction.



Title: RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the  Absence of First-order Echoes
Room geometry is important prior information for implementing realistic 3D
audio rendering. For this reason, various room geometry inference (RGI) methods
have been developed by utilizing the time of arrival (TOA) or time difference
of arrival (TDOA) information in room impulse responses. However, the
conventional RGI technique poses several assumptions, such as convex room
shapes, the number of walls known in priori, and the visibility of first-order
reflections. In this work, we introduce the deep neural network (DNN), RGI-Net,
which can estimate room geometries without the aforementioned assumptions.
RGI-Net learns and exploits complex relationships between high-order
reflections in room impulse responses (RIRs) and, thus, can estimate room
shapes even when the shape is non-convex or first-order reflections are missing
in the RIRs. The network takes RIRs measured from a compact audio device
equipped with a circular microphone array and a single loudspeaker, which
greatly improves its practical applicability. RGI-Net includes the evaluation
network that separately evaluates the presence probability of walls, so the
geometry inference is possible without prior knowledge of the number of walls.



Title: MultiWay-Adapater: Adapting large-scale multi-modal models for scalable  image-text retrieval
As the size of Large Multi-Modal Models (LMMs) increases consistently, the
adaptation of these pre-trained models to specialized tasks has become a
computationally and memory-intensive challenge. Traditional fine-tuning methods
require isolated, exhaustive retuning for each new task, limiting the models'
versatility. Moreover, current efficient adaptation techniques often overlook
modality alignment, focusing only on the knowledge extraction of new tasks. To
tackle these issues, we introduce Multiway-Adapter, an innovative framework
incorporating an 'Alignment Enhancer' to deepen modality alignment, enabling
high transferability without tuning pre-trained parameters. Our method adds
fewer than 1.25\% of additional parameters to LMMs, exemplified by the BEiT-3
model in our study. This leads to superior zero-shot image-text retrieval
performance compared to fully fine-tuned models, while achieving up to a 57\%
reduction in fine-tuning time. Our approach offers a resource-efficient and
effective adaptation pathway for LMMs, broadening their applicability. The
source code is publicly available at:
\url{https://github.com/longkukuhi/MultiWay-Adapter}.



Title: Are We Using Autoencoders in a Wrong Way?
Autoencoders are certainly among the most studied and used Deep Learning
models: the idea behind them is to train a model in order to reconstruct the
same input data. The peculiarity of these models is to compress the information
through a bottleneck, creating what is called Latent Space. Autoencoders are
generally used for dimensionality reduction, anomaly detection and feature
extraction. These models have been extensively studied and updated, given their
high simplicity and power. Examples are (i) the Denoising Autoencoder, where
the model is trained to reconstruct an image from a noisy one; (ii) Sparse
Autoencoder, where the bottleneck is created by a regularization term in the
loss function; (iii) Variational Autoencoder, where the latent space is used to
generate new consistent data. In this article, we revisited the standard
training for the undercomplete Autoencoder modifying the shape of the latent
space without using any explicit regularization term in the loss function. We
forced the model to reconstruct not the same observation in input, but another
one sampled from the same class distribution. We also explored the behaviour of
the latent space in the case of reconstruction of a random sample from the
whole dataset.



Title: OutRank: Speeding up AutoML-based Model Search for Large Sparse Data  sets with Cardinality-aware Feature Ranking
The design of modern recommender systems relies on understanding which parts
of the feature space are relevant for solving a given recommendation task.
However, real-world data sets in this domain are often characterized by their
large size, sparsity, and noise, making it challenging to identify meaningful
signals. Feature ranking represents an efficient branch of algorithms that can
help address these challenges by identifying the most informative features and
facilitating the automated search for more compact and better-performing models
(AutoML). We introduce OutRank, a system for versatile feature ranking and data
quality-related anomaly detection. OutRank was built with categorical data in
mind, utilizing a variant of mutual information that is normalized with regard
to the noise produced by features of the same cardinality. We further extend
the similarity measure by incorporating information on feature similarity and
combined relevance. The proposed approach's feasibility is demonstrated by
speeding up the state-of-the-art AutoML system on a synthetic data set with no
performance loss. Furthermore, we considered a real-life click-through-rate
prediction data set where it outperformed strong baselines such as random
forest-based approaches. The proposed approach enables exploration of up to
300% larger feature spaces compared to AutoML-only approaches, enabling faster
search for better models on off-the-shelf hardware.



Title: Rail Crack Propagation Forecasting Using Multi-horizons RNNs
The prediction of rail crack length propagation plays a crucial role in the
maintenance and safety assessment of materials and structures. Traditional
methods rely on physical models and empirical equations such as Paris law,
which often have limitations in capturing the complex nature of crack growth.
In recent years, machine learning techniques, particularly Recurrent Neural
Networks (RNNs), have emerged as promising methods for time series forecasting.
They allow to model time series data, and to incorporate exogenous variables
into the model. The proposed approach involves collecting real data on the
French rail network that includes historical crack length measurements, along
with relevant exogenous factors that may influence crack growth. First, a
pre-processing phase was performed to prepare a consistent data set for
learning. Then, a suitable Bayesian multi-horizons recurrent architecture was
designed to model the crack propagation phenomenon. Obtained results show that
the Multi-horizons model outperforms state-of-the-art models such as LSTM and
GRU.



Title: Les Houches Lectures on Deep Learning at Large & Infinite Width
These lectures, presented at the 2022 Les Houches Summer School on
Statistical Physics and Machine Learning, focus on the infinite-width limit and
large-width regime of deep neural networks. Topics covered include various
statistical and dynamical properties of these networks. In particular, the
lecturers discuss properties of random deep neural networks; connections
between trained deep neural networks, linear models, kernels, and Gaussian
processes that arise in the infinite-width limit; and perturbative and
non-perturbative treatments of large but finite-width networks, at
initialization and after training.



Title: Deep Learning Overloaded Vehicle Identification for Long Span Bridges  Based on Structural Health Monitoring Data
Overloaded vehicles bring great harm to transportation infrastructures. BWIM
(bridge weigh-in-motion) method for overloaded vehicle identification is
getting more popular because it can be implemented without interruption to the
traffic. However, its application is still limited because its effectiveness
largely depends on professional knowledge and extra information, and is
susceptible to occurrence of multiple vehicles. In this paper, a deep learning
based overloaded vehicle identification approach (DOVI) is proposed, with the
purpose of overloaded vehicle identification for long-span bridges by the use
of structural health monitoring data. The proposed DOVI model uses temporal
convolutional architectures to extract the spatial and temporal features of the
input sequence data, thus provides an end-to-end overloaded vehicle
identification solution which neither needs the influence line nor needs to
obtain velocity and wheelbase information in advance and can be applied under
the occurrence of multiple vehicles. Model evaluations are conducted on a
simply supported beam and a long-span cable-stayed bridge under random traffic
flow. Results demonstrate that the proposed deep-learning overloaded vehicle
identification approach has better effectiveness and robustness, compared with
other machine learning and deep learning approaches.



Title: DeViL: Decoding Vision features into Language
Post-hoc explanation methods have often been criticised for abstracting away
the decision-making process of deep neural networks. In this work, we would
like to provide natural language descriptions for what different layers of a
vision backbone have learned. Our DeViL method decodes vision features into
language, not only highlighting the attribution locations but also generating
textual descriptions of visual features at different layers of the network. We
train a transformer network to translate individual image features of any
vision layer into a prompt that a separate off-the-shelf language model decodes
into natural language. By employing dropout both per-layer and
per-spatial-location, our model can generalize training on image-text pairs to
generate localized explanations. As it uses a pre-trained language model, our
approach is fast to train, can be applied to any vision backbone, and produces
textual descriptions at different layers of the vision network. Moreover, DeViL
can create open-vocabulary attribution maps corresponding to words or phrases
even outside the training scope of the vision model. We demonstrate that DeViL
generates textual descriptions relevant to the image content on CC3M surpassing
previous lightweight captioning models and attribution maps uncovering the
learned concepts of the vision backbone. Finally, we show DeViL also
outperforms the current state-of-the-art on the neuron-wise descriptions of the
MILANNOTATIONS dataset. Code available at
https://github.com/ExplainableML/DeViL



Title: Corgi^2: A Hybrid Offline-Online Approach To Storage-Aware Data  Shuffling For SGD
When using Stochastic Gradient Descent (SGD) for training machine learning
models, it is often crucial to provide the model with examples sampled at
random from the dataset. However, for large datasets stored in the cloud,
random access to individual examples is often costly and inefficient. A recent
work \cite{corgi}, proposed an online shuffling algorithm called CorgiPile,
which greatly improves efficiency of data access, at the cost some performance
loss, which is particularly apparent for large datasets stored in homogeneous
shards (e.g., video datasets). In this paper, we introduce a novel two-step
partial data shuffling strategy for SGD which combines an offline iteration of
the CorgiPile method with a subsequent online iteration. Our approach enjoys
the best of both worlds: it performs similarly to SGD with random access (even
for homogenous data) without compromising the data access efficiency of
CorgiPile. We provide a comprehensive theoretical analysis of the convergence
properties of our method and demonstrate its practical advantages through
experimental results.



Title: Unveiling Theory of Mind in Large Language Models: A Parallel to Single  Neurons in the Human Brain
With their recent development, large language models (LLMs) have been found
to exhibit a certain level of Theory of Mind (ToM), a complex cognitive
capacity that is related to our conscious mind and that allows us to infer
another's beliefs and perspective. While human ToM capabilities are believed to
derive from the neural activity of a broadly interconnected brain network,
including that of dorsal medial prefrontal cortex (dmPFC) neurons, the precise
processes underlying LLM's capacity for ToM or their similarities with that of
humans remains largely unknown. In this study, we drew inspiration from the
dmPFC neurons subserving human ToM and employed a similar methodology to
examine whether LLMs exhibit comparable characteristics. Surprisingly, our
analysis revealed a striking resemblance between the two, as hidden embeddings
(artificial neurons) within LLMs started to exhibit significant responsiveness
to either true- or false-belief trials, suggesting their ability to represent
another's perspective. These artificial embedding responses were closely
correlated with the LLMs' performance during the ToM tasks, a property that was
dependent on the size of the models. Further, the other's beliefs could be
accurately decoded using the entire embeddings, indicating the presence of the
embeddings' ToM capability at the population level. Together, our findings
revealed an emergent property of LLMs' embeddings that modified their
activities in response to ToM features, offering initial evidence of a parallel
between the artificial model and neurons in the human brain.



Title: Fine-grained Affective Processing Capabilities Emerging from Large  Language Models
Large language models, in particular generative pre-trained transformers
(GPTs), show impressive results on a wide variety of language-related tasks. In
this paper, we explore ChatGPT's zero-shot ability to perform affective
computing tasks using prompting alone. We show that ChatGPT a) performs
meaningful sentiment analysis in the Valence, Arousal and Dominance dimensions,
b) has meaningful emotion representations in terms of emotion categories and
these affective dimensions, and c) can perform basic appraisal-based emotion
elicitation of situations based on a prompt-based computational implementation
of the OCC appraisal model. These findings are highly relevant: First, they
show that the ability to solve complex affect processing tasks emerges from
language-based token prediction trained on extensive data sets. Second, they
show the potential of large language models for simulating, processing and
analyzing human emotions, which has important implications for various
applications such as sentiment analysis, socially interactive agents, and
social robotics.



Title: Prompt me a Dataset: An investigation of text-image prompting for  historical image dataset creation using foundation models
In this paper, we present a pipeline for image extraction from historical
documents using foundation models, and evaluate text-image prompts and their
effectiveness on humanities datasets of varying levels of complexity. The
motivation for this approach stems from the high interest of historians in
visual elements printed alongside historical texts on the one hand, and from
the relative lack of well-annotated datasets within the humanities when
compared to other domains. We propose a sequential approach that relies on
GroundDINO and Meta's Segment-Anything-Model (SAM) to retrieve a significant
portion of visual data from historical documents that can then be used for
downstream development tasks and dataset creation, as well as evaluate the
effect of different linguistic prompts on the resulting detections.



Title: No Data Augmentation? Alternative Regularizations for Effective Training  on Small Datasets
Solving image classification tasks given small training datasets remains an
open challenge for modern computer vision. Aggressive data augmentation and
generative models are among the most straightforward approaches to overcoming
the lack of data. However, the first fails to be agnostic to varying image
domains, while the latter requires additional compute and careful design. In
this work, we study alternative regularization strategies to push the limits of
supervised learning on small image classification datasets. In particular,
along with the model size and training schedule scaling, we employ a heuristic
to select (semi) optimal learning rate and weight decay couples via the norm of
model parameters. By training on only 1% of the original CIFAR-10 training set
(i.e., 50 images per class) and testing on ciFAIR-10, a variant of the original
CIFAR without duplicated images, we reach a test accuracy of 66.5%, on par with
the best state-of-the-art methods.



Title: On the Robustness of Post-hoc GNN Explainers to Label Noise
Proposed as a solution to the inherent black-box limitations of graph neural
networks (GNNs), post-hoc GNN explainers aim to provide precise and insightful
explanations of the behaviours exhibited by trained GNNs. Despite their recent
notable advancements in academic and industrial contexts, the robustness of
post-hoc GNN explainers remains unexplored when confronted with label noise. To
bridge this gap, we conduct a systematic empirical investigation to evaluate
the efficacy of diverse post-hoc GNN explainers under varying degrees of label
noise. Our results reveal several key insights: Firstly, post-hoc GNN
explainers are susceptible to label perturbations. Secondly, even minor levels
of label noise, inconsequential to GNN performance, harm the quality of
generated explanations substantially. Lastly, we engage in a discourse
regarding the progressive recovery of explanation effectiveness with escalating
noise levels.



Title: Interdisciplinary Fairness in Imbalanced Research Proposal Topic  Inference: A Hierarchical Transformer-based Method with Selective  Interpolation
The objective of topic inference in research proposals aims to obtain the
most suitable disciplinary division from the discipline system defined by a
funding agency. The agency will subsequently find appropriate peer review
experts from their database based on this division. Automated topic inference
can reduce human errors caused by manual topic filling, bridge the knowledge
gap between funding agencies and project applicants, and improve system
efficiency. Existing methods focus on modeling this as a hierarchical
multi-label classification problem, using generative models to iteratively
infer the most appropriate topic information. However, these methods overlook
the gap in scale between interdisciplinary research proposals and
non-interdisciplinary ones, leading to an unjust phenomenon where the automated
inference system categorizes interdisciplinary proposals as
non-interdisciplinary, causing unfairness during the expert assignment. How can
we address this data imbalance issue under a complex discipline system and
hence resolve this unfairness? In this paper, we implement a topic label
inference system based on a Transformer encoder-decoder architecture.
Furthermore, we utilize interpolation techniques to create a series of
pseudo-interdisciplinary proposals from non-interdisciplinary ones during
training based on non-parametric indicators such as cross-topic probabilities
and topic occurrence probabilities. This approach aims to reduce the bias of
the system during model training. Finally, we conduct extensive experiments on
a real-world dataset to verify the effectiveness of the proposed method. The
experimental results demonstrate that our training strategy can significantly
mitigate the unfairness generated in the topic inference task.



Title: Softmax Bias Correction for Quantized Generative Models
Post-training quantization (PTQ) is the go-to compression technique for large
generative models, such as stable diffusion or large language models. PTQ
methods commonly keep the softmax activation in higher precision as it has been
shown to be very sensitive to quantization noise. However, this can lead to a
significant runtime and power overhead during inference on resource-constraint
edge devices. In this work, we investigate the source of the softmax
sensitivity to quantization and show that the quantization operation leads to a
large bias in the softmax output, causing accuracy degradation. To overcome
this issue, we propose an offline bias correction technique that improves the
quantizability of softmax without additional compute during deployment, as it
can be readily absorbed into the quantization parameters. We demonstrate the
effectiveness of our method on stable diffusion v1.5 and 125M-size OPT language
model, achieving significant accuracy improvement for 8-bit quantized softmax.



Title: Hybrid data driven/thermal simulation model for comfort assessment
Machine learning models improve the speed and quality of physical models.
However, they require a large amount of data, which is often difficult and
costly to acquire. Predicting thermal comfort, for example, requires a
controlled environment, with participants presenting various characteristics
(age, gender, ...). This paper proposes a method for hybridizing real data with
simulated data for thermal comfort prediction. The simulations are performed
using Modelica Language. A benchmarking study is realized to compare different
machine learning methods. Obtained results look promising with an F1 score of
0.999 obtained using the random forest model.



Title: On the size of irredundant propagation complete CNF formulas
We investigate propagation complete (PC) CNF formulas for a symmetric
definite Horn function of $n$ variables and demonstrate that the minimum size
of these formulas is closely related to specific covering numbers, namely, to
the smallest number of $k$-subsets of an $n$-set covering all $(k-1)$-subsets
for a suitable $k$. As a consequence, we demonstrate an irredundant PC formula
whose size is larger than the size of a smallest PC formula for the same
function by a factor $\Omega(n/\ln n)$. This complements a known polynomial
upper bound on this factor.



Title: 3D View Prediction Models of the Dorsal Visual Stream
Deep neural network representations align well with brain activity in the
ventral visual stream. However, the primate visual system has a distinct dorsal
processing stream with different functional properties. To test if a model
trained to perceive 3D scene geometry aligns better with neural responses in
dorsal visual areas, we trained a self-supervised geometry-aware recurrent
neural network (GRNN) to predict novel camera views using a 3D feature memory.
We compared GRNN to self-supervised baseline models that have been shown to
align well with ventral regions using the large-scale fMRI Natural Scenes
Dataset (NSD). We found that while the baseline models accounted better for
ventral brain regions, GRNN accounted for a greater proportion of variance in
dorsal brain regions. Our findings demonstrate the potential for using
task-relevant models to probe representational differences across visual
streams.



Title: Neural-Singular-Hessian: Implicit Neural Representation of Unoriented  Point Clouds by Enforcing Singular Hessian
Neural implicit representation is a promising approach for reconstructing
surfaces from point clouds. Existing methods combine various regularization
terms, such as the Eikonal and Laplacian energy terms, to enforce the learned
neural function to possess the properties of a Signed Distance Function (SDF).
However, inferring the actual topology and geometry of the underlying surface
from poor-quality unoriented point clouds remains challenging. In accordance
with Differential Geometry, the Hessian of the SDF is singular for points
within the differential thin-shell space surrounding the surface. Our approach
enforces the Hessian of the neural implicit function to have a zero determinant
for points near the surface. This technique aligns the gradients for a
near-surface point and its on-surface projection point, producing a rough but
faithful shape within just a few iterations. By annealing the weight of the
singular-Hessian term, our approach ultimately produces a high-fidelity
reconstruction result. Extensive experimental results demonstrate that our
approach effectively suppresses ghost geometry and recovers details from
unoriented point clouds with better expressiveness than existing fitting-based
methods.



Title: Marginalized Importance Sampling for Off-Environment Policy Evaluation
Reinforcement Learning (RL) methods are typically sample-inefficient, making
it challenging to train and deploy RL-policies in real world robots. Even a
robust policy trained in simulation, requires a real-world deployment to assess
their performance. This paper proposes a new approach to evaluate the
real-world performance of agent policies without deploying them in the real
world. The proposed approach incorporates a simulator along with real-world
offline data to evaluate the performance of any policy using the framework of
Marginalized Importance Sampling (MIS). Existing MIS methods face two
challenges: (1) large density ratios that deviate from a reasonable range and
(2) indirect supervision, where the ratio needs to be inferred indirectly, thus
exacerbating estimation error. Our approach addresses these challenges by
introducing the target policy's occupancy in the simulator as an intermediate
variable and learning the density ratio as the product of two terms that can be
learned separately. The first term is learned with direct supervision and the
second term has a small magnitude, thus making it easier to run. We analyze the
sample complexity as well as error propagation of our two step-procedure.
Furthermore, we empirically evaluate our approach on Sim2Sim environments such
as Cartpole, Reacher and Half-Cheetah. Our results show that our method
generalizes well across a variety of Sim2Sim gap, target policies and offline
data collection policies. We also demonstrate the performance of our algorithm
on a Sim2Real task of validating the performance of a 7 DOF robotic arm using
offline data along with a gazebo based arm simulator.



Title: DiscoverPath: A Knowledge Refinement and Retrieval System for  Interdisciplinarity on Biomedical Research
The exponential growth in scholarly publications necessitates advanced tools
for efficient article retrieval, especially in interdisciplinary fields where
diverse terminologies are used to describe similar research. Traditional
keyword-based search engines often fall short in assisting users who may not be
familiar with specific terminologies. To address this, we present a knowledge
graph-based paper search engine for biomedical research to enhance the user
experience in discovering relevant queries and articles. The system, dubbed
DiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS)
tagging to extract terminologies and relationships from article abstracts to
create a KG. To reduce information overload, DiscoverPath presents users with a
focused subgraph containing the queried entity and its neighboring nodes and
incorporates a query recommendation system, enabling users to iteratively
refine their queries. The system is equipped with an accessible Graphical User
Interface that provides an intuitive visualization of the KG, query
recommendations, and detailed article information, enabling efficient article
retrieval, thus fostering interdisciplinary knowledge exploration. DiscoverPath
is open-sourced at https://github.com/ynchuang/DiscoverPath.



Title: One Wide Feedforward is All You Need
The Transformer architecture has two main non-embedding components: Attention
and the Feed Forward Network (FFN). Attention captures interdependencies
between words regardless of their position, while the FFN non-linearly
transforms each input token independently. In this work we explore the role of
the FFN, and find that despite taking up a significant fraction of the model's
parameters, it is highly redundant. Concretely, we are able to substantially
reduce the number of parameters with only a modest drop in accuracy by removing
the FFN on the decoder layers and sharing a single FFN across the encoder.
Finally we scale this architecture back to its original size by increasing the
hidden dimension of the shared FFN, achieving substantial gains in both
accuracy and latency with respect to the original Transformer Big.



Title: Efficient Defense Against Model Stealing Attacks on Convolutional Neural  Networks
Model stealing attacks have become a serious concern for deep learning
models, where an attacker can steal a trained model by querying its black-box
API. This can lead to intellectual property theft and other security and
privacy risks. The current state-of-the-art defenses against model stealing
attacks suggest adding perturbations to the prediction probabilities. However,
they suffer from heavy computations and make impracticable assumptions about
the adversary. They often require the training of auxiliary models. This can be
time-consuming and resource-intensive which hinders the deployment of these
defenses in real-world applications. In this paper, we propose a simple yet
effective and efficient defense alternative. We introduce a heuristic approach
to perturb the output probabilities. The proposed defense can be easily
integrated into models without additional training. We show that our defense is
effective in defending against three state-of-the-art stealing attacks. We
evaluate our approach on large and quantized (i.e., compressed) Convolutional
Neural Networks (CNNs) trained on several vision datasets. Our technique
outperforms the state-of-the-art defenses with a $\times37$ faster inference
latency without requiring any additional model and with a low impact on the
model's performance. We validate that our defense is also effective for
quantized CNNs targeting edge devices.



Title: BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet  Fluorescence Microscopy with Image Formation Prior
Light-sheet fluorescence microscopy (LSFM), a planar illumination technique
that enables high-resolution imaging of samples, experiences defocused image
quality caused by light scattering when photons propagate through thick
tissues. To circumvent this issue, dualview imaging is helpful. It allows
various sections of the specimen to be scanned ideally by viewing the sample
from opposing orientations. Recent image fusion approaches can then be applied
to determine in-focus pixels by comparing image qualities of two views locally
and thus yield spatially inconsistent focus measures due to their limited
field-of-view. Here, we propose BigFUSE, a global context-aware image fuser
that stabilizes image fusion in LSFM by considering the global impact of photon
propagation in the specimen while determining focus-defocus based on local
image qualities. Inspired by the image formation prior in dual-view LSFM, image
fusion is considered as estimating a focus-defocus boundary using Bayes
Theorem, where (i) the effect of light scattering onto focus measures is
included within Likelihood; and (ii) the spatial consistency regarding
focus-defocus is imposed in Prior. The expectation-maximum algorithm is then
adopted to estimate the focus-defocus boundary. Competitive experimental
results show that BigFUSE is the first dual-view LSFM fuser that is able to
exclude structured artifacts when fusing information, highlighting its
abilities of automatic image fusion.



Title: Efficient Query-Based Attack against ML-Based Android Malware Detection  under Zero Knowledge Setting
The widespread adoption of the Android operating system has made malicious
Android applications an appealing target for attackers. Machine learning-based
(ML-based) Android malware detection (AMD) methods are crucial in addressing
this problem; however, their vulnerability to adversarial examples raises
concerns. Current attacks against ML-based AMD methods demonstrate remarkable
performance but rely on strong assumptions that may not be realistic in
real-world scenarios, e.g., the knowledge requirements about feature space,
model parameters, and training dataset. To address this limitation, we
introduce AdvDroidZero, an efficient query-based attack framework against
ML-based AMD methods that operates under the zero knowledge setting. Our
extensive evaluation shows that AdvDroidZero is effective against various
mainstream ML-based AMD methods, in particular, state-of-the-art such methods
and real-world antivirus solutions.



Title: On the Planning, Search, and Memorization Capabilities of Large Language  Models
The rapid advancement of large language models, such as the Generative
Pre-trained Transformer (GPT) series, has had significant implications across
various disciplines. In this study, we investigate the potential of the
state-of-the-art large language model (GPT-4) for planning tasks. We explore
its effectiveness in multiple planning subfields, highlighting both its
strengths and limitations. Through a comprehensive examination, we identify
areas where large language models excel in solving planning problems and reveal
the constraints that limit their applicability. Our empirical analysis focuses
on GPT-4's performance in planning domain extraction, graph search path
planning, and adversarial planning. We then propose a way of fine-tuning a
domain-specific large language model to improve its Chain of Thought (CoT)
capabilities for the above-mentioned tasks. The results provide valuable
insights into the potential applications of large language models in the
planning domain and pave the way for future research to overcome their
limitations and expand their capabilities.



Title: Inferring Actual Treatment Pathways from Patient Records
Treatment pathways are step-by-step plans outlining the recommended medical
care for specific diseases; they get revised when different treatments are
found to improve patient outcomes. Examining health records is an important
part of this revision process, but inferring patients' actual treatments from
health data is challenging due to complex event-coding schemes and the absence
of pathway-related annotations. This study aims to infer the actual treatment
steps for a particular patient group from administrative health records (AHR) -
a common form of tabular healthcare data - and address several technique- and
methodology-based gaps in treatment pathway-inference research. We introduce
Defrag, a method for examining AHRs to infer the real-world treatment steps for
a particular patient group. Defrag learns the semantic and temporal meaning of
healthcare event sequences, allowing it to reliably infer treatment steps from
complex healthcare data. To our knowledge, Defrag is the first
pathway-inference method to utilise a neural network (NN), an approach made
possible by a novel, self-supervised learning objective. We also developed a
testing and validation framework for pathway inference, which we use to
characterise and evaluate Defrag's pathway inference ability and compare
against baselines. We demonstrate Defrag's effectiveness by identifying
best-practice pathway fragments for breast cancer, lung cancer, and melanoma in
public healthcare records. Additionally, we use synthetic data experiments to
demonstrate the characteristics of the Defrag method, and to compare Defrag to
several baselines where it significantly outperforms non-NN-based methods.
Defrag significantly outperforms several existing pathway-inference methods and
offers an innovative and effective approach for inferring treatment pathways
from AHRs. Open-source code is provided to encourage further research in this
area.



Title: Towards General and Efficient Online Tuning for Spark
The distributed data analytic system -- Spark is a common choice for
processing massive volumes of heterogeneous data, while it is challenging to
tune its parameters to achieve high performance. Recent studies try to employ
auto-tuning techniques to solve this problem but suffer from three issues:
limited functionality, high overhead, and inefficient search. In this paper, we present a general and efficient Spark tuning framework that
can deal with the three issues simultaneously. First, we introduce a
generalized tuning formulation, which can support multiple tuning goals and
constraints conveniently, and a Bayesian optimization (BO) based solution to
solve this generalized optimization problem. Second, to avoid high overhead
from additional offline evaluations in existing methods, we propose to tune
parameters along with the actual periodic executions of each job (i.e., online
evaluations). To ensure safety during online job executions, we design a safe
configuration acquisition method that models the safe region. Finally, three
innovative techniques are leveraged to further accelerate the search process:
adaptive sub-space generation, approximate gradient descent, and meta-learning
method. We have implemented this framework as an independent cloud service, and
applied it to the data platform in Tencent. The empirical results on both
public benchmarks and large-scale production tasks demonstrate its superiority
in terms of practicality, generality, and efficiency. Notably, this service
saves an average of 57.00% memory cost and 34.93% CPU cost on 25K in-production
tasks within 20 iterations, respectively.



Title: SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and  Building Change Detection
Synthetic datasets, recognized for their cost effectiveness, play a pivotal
role in advancing computer vision tasks and techniques. However, when it comes
to remote sensing image processing, the creation of synthetic datasets becomes
challenging due to the demand for larger-scale and more diverse 3D models. This
complexity is compounded by the difficulties associated with real remote
sensing datasets, including limited data acquisition and high annotation costs,
which amplifies the need for high-quality synthetic alternatives. To address
this, we present SyntheWorld, a synthetic dataset unparalleled in quality,
diversity, and scale. It includes 40,000 images with submeter-level pixels and
fine-grained land cover annotations of eight categories, and it also provides
40,000 pairs of bitemporal image pairs with building change annotations for
building change detection task. We conduct experiments on multiple benchmark
remote sensing datasets to verify the effectiveness of SyntheWorld and to
investigate the conditions under which our synthetic data yield advantages. We
will release SyntheWorld to facilitate remote sensing image processing
research.



Title: Regret Analysis of Policy Gradient Algorithm for Infinite Horizon  Average Reward Markov Decision Processes
In this paper, we consider an infinite horizon average reward Markov Decision
Process (MDP). Distinguishing itself from existing works within this context,
our approach harnesses the power of the general policy gradient-based
algorithm, liberating it from the constraints of assuming a linear MDP
structure. We propose a policy gradient-based algorithm and show its global
convergence property. We then prove that the proposed algorithm has
$\tilde{\mathcal{O}}({T}^{3/4})$ regret. Remarkably, this paper marks a
pioneering effort by presenting the first exploration into regret-bound
computation for the general parameterized policy gradient algorithm in the
context of average reward scenarios.



Title: Provably safe systems: the only path to controllable AGI
We describe a path to humanity safely thriving with powerful Artificial
General Intelligences (AGIs) by building them to provably satisfy
human-specified requirements. We argue that this will soon be technically
feasible using advanced AI for formal verification and mechanistic
interpretability. We further argue that it is the only path which guarantees
safe controlled AGI. We end with a list of challenge problems whose solution
would contribute to this positive outcome and invite readers to join in this
work.



Title: CodeApex: A Bilingual Programming Evaluation Benchmark for Large  Language Models
With the emergence of Large Language Models (LLMs), there has been a
significant improvement in the programming capabilities of models, attracting
growing attention from researchers. We propose CodeApex, a bilingual benchmark
dataset focusing on the programming comprehension and code generation abilities
of LLMs. CodeApex comprises three types of multiple-choice questions:
conceptual understanding, commonsense reasoning, and multi-hop reasoning,
designed to evaluate LLMs on programming comprehension tasks. Additionally,
CodeApex utilizes algorithmic questions and corresponding test cases to assess
the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs,
including both general-purpose and specialized models. GPT exhibits the best
programming capabilities, achieving approximate accuracies of 50% and 56% on
the two tasks, respectively. There is still significant room for improvement in
programming tasks. We hope that CodeApex can serve as a reference for
evaluating the coding capabilities of LLMs, further promoting their development
and growth. Datasets are released at
\url{https://github.com/APEXLAB/CodeApex.git}. CodeApex submission website is
\url{https://apex.sjtu.edu.cn/codeapex/}.



Title: Dynamic Brain Transformer with Multi-level Attention for Functional  Brain Network Analysis
Recent neuroimaging studies have highlighted the importance of
network-centric brain analysis, particularly with functional magnetic resonance
imaging. The emergence of Deep Neural Networks has fostered a substantial
interest in predicting clinical outcomes and categorizing individuals based on
brain networks. However, the conventional approach involving static brain
network analysis offers limited potential in capturing the dynamism of brain
function. Although recent studies have attempted to harness dynamic brain
networks, their high dimensionality and complexity present substantial
challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer
(DART), which combines static and dynamic brain networks for more effective and
nuanced brain function analysis. Our model uses the static brain network as a
baseline, integrating dynamic brain networks to enhance performance against
traditional methods. We innovatively employ attention mechanisms, enhancing
model explainability and exploiting the dynamic brain network's temporal
variations. The proposed approach offers a robust solution to the low
signal-to-noise ratio of blood-oxygen-level-dependent signals, a recurring
issue in direct DNN modeling. It also provides valuable insights into which
brain circuits or dynamic networks contribute more to final predictions. As
such, DRAT shows a promising direction in neuroimaging studies, contributing to
the comprehensive understanding of brain organization and the role of neural
circuits.



Title: OHQ: On-chip Hardware-aware Quantization
Quantization emerges as one of the most promising approaches for deploying
advanced deep models on resource-constrained hardware. Mixed-precision
quantization leverages multiple bit-width architectures to unleash the accuracy
and efficiency potential of quantized models. However, existing mixed-precision
quantization suffers exhaustive search space that causes immense computational
overhead. The quantization process thus relies on separate high-performance
devices rather than locally, which also leads to a significant gap between the
considered hardware metrics and the real deployment.In this paper, we propose
an On-chip Hardware-aware Quantization (OHQ) framework that performs
hardware-aware mixed-precision quantization without accessing online devices.
First, we construct the On-chip Quantization Awareness (OQA) pipeline, enabling
perceive the actual efficiency metrics of the quantization operator on the
hardware.Second, we propose Mask-guided Quantization Estimation (MQE) technique
to efficiently estimate the accuracy metrics of operators under the constraints
of on-chip-level computing power.By synthesizing network and hardware insights
through linear programming, we obtain optimized bit-width configurations.
Notably, the quantization process occurs on-chip entirely without any
additional computing devices and data access. We demonstrate accelerated
inference after quantization for various architectures and compression ratios,
achieving 70% and 73% accuracy for ResNet-18 and MobileNetV3, respectively. OHQ
improves latency by 15~30% compared to INT8 on deployment.



Title: RADIO: Reference-Agnostic Dubbing Video Synthesis
One of the most challenging problems in audio-driven talking head generation
is achieving high-fidelity detail while ensuring precise synchronization. Given
only a single reference image, extracting meaningful identity attributes
becomes even more challenging, often causing the network to mirror the facial
and lip structures too closely. To address these issues, we introduce RADIO, a
framework engineered to yield high-quality dubbed videos regardless of the pose
or expression in reference images. The key is to modulate the decoder layers
using latent space composed of audio and reference features. Additionally, we
incorporate ViT blocks into the decoder to emphasize high-fidelity details,
especially in the lip region. Our experimental results demonstrate that RADIO
displays high synchronization without the loss of fidelity. Especially in harsh
scenarios where the reference frame deviates significantly from the ground
truth, our method outperforms state-of-the-art methods, highlighting its
robustness. Pre-trained model and codes will be made public after the review.



Title: Linear Regression using Heterogeneous Data Batches
In many learning applications, data are collected from multiple sources, each
providing a \emph{batch} of samples that by itself is insufficient to learn its
input-output relationship. A common approach assumes that the sources fall in
one of several unknown subgroups, each with an unknown input distribution and
input-output relationship. We consider one of this setup's most fundamental and
important manifestations where the output is a noisy linear combination of the
inputs, and there are $k$ subgroups, each with its own regression vector. Prior
work~\cite{kong2020meta} showed that with abundant small-batches, the
regression vectors can be learned with only few, $\tilde\Omega( k^{3/2})$,
batches of medium-size with $\tilde\Omega(\sqrt k)$ samples each. However, the
paper requires that the input distribution for all $k$ subgroups be isotropic
Gaussian, and states that removing this assumption is an ``interesting and
challenging problem". We propose a novel gradient-based algorithm that improves
on the existing results in several ways. It extends the applicability of the
algorithm by: (1) allowing the subgroups' underlying input distributions to be
different, unknown, and heavy-tailed; (2) recovering all subgroups followed by
a significant proportion of batches even for infinite $k$; (3) removing the
separation requirement between the regression vectors; (4) reducing the number
of batches and allowing smaller batch sizes.



Title: Graph-Based Interaction-Aware Multimodal 2D Vehicle Trajectory  Prediction using Diffusion Graph Convolutional Networks
Predicting vehicle trajectories is crucial for ensuring automated vehicle
operation efficiency and safety, particularly on congested multi-lane highways.
In such dynamic environments, a vehicle's motion is determined by its
historical behaviors as well as interactions with surrounding vehicles. These
intricate interactions arise from unpredictable motion patterns, leading to a
wide range of driving behaviors that warrant in-depth investigation. This study
presents the Graph-based Interaction-aware Multi-modal Trajectory Prediction
(GIMTP) framework, designed to probabilistically predict future vehicle
trajectories by effectively capturing these interactions. Within this
framework, vehicles' motions are conceptualized as nodes in a time-varying
graph, and the traffic interactions are represented by a dynamic adjacency
matrix. To holistically capture both spatial and temporal dependencies embedded
in this dynamic adjacency matrix, the methodology incorporates the Diffusion
Graph Convolutional Network (DGCN), thereby providing a graph embedding of both
historical states and future states. Furthermore, we employ a driving
intention-specific feature fusion, enabling the adaptive integration of
historical and future embeddings for enhanced intention recognition and
trajectory prediction. This model gives two-dimensional predictions for each
mode of longitudinal and lateral driving behaviors and offers probabilistic
future paths with corresponding probabilities, addressing the challenges of
complex vehicle interactions and multi-modality of driving behaviors.
Validation using real-world trajectory datasets demonstrates the efficiency and
potential.



Title: sasdim: self-adaptive noise scaling diffusion model for spatial time  series imputation
Spatial time series imputation is critically important to many real
applications such as intelligent transportation and air quality monitoring.
Although recent transformer and diffusion model based approaches have achieved
significant performance gains compared with conventional statistic based
methods, spatial time series imputation still remains as a challenging issue
due to the complex spatio-temporal dependencies and the noise uncertainty of
the spatial time series data. Especially, recent diffusion process based models
may introduce random noise to the imputations, and thus cause negative impact
on the model performance. To this end, we propose a self-adaptive noise scaling
diffusion model named SaSDim to more effectively perform spatial time series
imputation. Specially, we propose a new loss function that can scale the noise
to the similar intensity, and propose the across spatial-temporal global
convolution module to more effectively capture the dynamic spatial-temporal
dependencies. Extensive experiments conducted on three real world datasets
verify the effectiveness of SaSDim by comparison with current state-of-the-art
baselines.



Title: Photonic Structures Optimization Using Highly Data-Efficient Deep  Learning: Application To Nanofin And Annular Groove Phase Masks
Metasurfaces offer a flexible framework for the manipulation of light
properties in the realm of thin film optics. Specifically, the polarization of
light can be effectively controlled through the use of thin phase plates. This
study aims to introduce a surrogate optimization framework for these devices.
The framework is applied to develop two kinds of vortex phase masks (VPMs)
tailored for application in astronomical high-contrast imaging. Computational
intelligence techniques are exploited to optimize the geometric features of
these devices. The large design space and computational limitations necessitate
the use of surrogate models like partial least squares Kriging, radial basis
functions, or neural networks. However, we demonstrate the inadequacy of these
methods in modeling the performance of VPMs. To address the shortcomings of
these methods, a data-efficient evolutionary optimization setup using a deep
neural network as a highly accurate and efficient surrogate model is proposed.
The optimization process in this study employs a robust particle swarm
evolutionary optimization scheme, which operates on explicit geometric
parameters of the photonic device. Through this approach, optimal designs are
developed for two design candidates. In the most complex case, evolutionary
optimization enables optimization of the design that would otherwise be
impractical (requiring too much simulations). In both cases, the surrogate
model improves the reliability and efficiency of the procedure, effectively
reducing the required number of simulations by up to 75% compared to
conventional optimization techniques.



Title: Analyzing domain shift when using additional data for the MICCAI KiTS23  Challenge
Using additional training data is known to improve the results, especially
for medical image 3D segmentation where there is a lack of training material
and the model needs to generalize well from few available data. However, the
new data could have been acquired using other instruments and preprocessed such
its distribution is significantly different from the original training data.
Therefore, we study techniques which ameliorate domain shift during training so
that the additional data becomes better usable for preprocessing and training
together with the original data. Our results show that transforming the
additional data using histogram matching has better results than using simple
normalization.



Title: Aggregating Correlated Estimations with (Almost) no Training
Many decision problems cannot be solved exactly and use several estimation
algorithms that assign scores to the different available options. The
estimation errors can have various correlations, from low (e.g. between two
very different approaches) to high (e.g. when using a given algorithm with
different hyperparameters). Most aggregation rules would suffer from this
diversity of correlations. In this article, we propose different aggregation
rules that take correlations into account, and we compare them to naive rules
in various experiments based on synthetic data. Our results show that when
sufficient information is known about the correlations between errors, a
maximum likelihood aggregation should be preferred. Otherwise, typically with
limited training data, we recommend a method that we call Embedded Voting (EV).



Title: iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and  Re-occurrence Preservation
Continuous-time dynamic graph modeling is a crucial task for many real-world
applications, such as financial risk management and fraud detection. Though
existing dynamic graph modeling methods have achieved satisfactory results,
they still suffer from three key limitations, hindering their scalability and
further applicability. i) Indiscriminate updating. For incoming edges, existing
methods would indiscriminately deal with them, which may lead to more time
consumption and unexpected noisy information. ii) Ineffective node-wise
long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a
backbone, which has been demonstrated to be incapable of fully capturing
node-wise long-term dependencies in event sequences. iii) Neglect of
re-occurrence patterns. Dynamic graphs involve the repeated occurrence of
neighbors that indicates their importance, which is disappointedly neglected by
existing methods. In this paper, we present iLoRE, a novel dynamic graph
modeling method with instant node-wise Long-term modeling and Re-occurrence
preservation. To overcome the indiscriminate updating issue, we introduce the
Adaptive Short-term Updater module that will automatically discard the useless
or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further
propose the Long-term Updater to realize more effective node-wise long-term
modeling, where we innovatively propose the Identity Attention mechanism to
empower a Transformer-based updater, bypassing the limited effectiveness of
typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are
also encoded into a graph module for informative representation learning, which
will further improve the expressiveness of our method. Our experimental results
on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic
graph modeling.



Title: Dynamic Early Exiting Predictive Coding Neural Networks
Internet of Things (IoT) sensors are nowadays heavily utilized in various
real-world applications ranging from wearables to smart buildings passing by
agrotechnology and health monitoring. With the huge amounts of data generated
by these tiny devices, Deep Learning (DL) models have been extensively used to
enhance them with intelligent processing. However, with the urge for smaller
and more accurate devices, DL models became too heavy to deploy. It is thus
necessary to incorporate the hardware's limited resources in the design
process. Therefore, inspired by the human brain known for its efficiency and
low power consumption, we propose a shallow bidirectional network based on
predictive coding theory and dynamic early exiting for halting further
computations when a performance threshold is surpassed. We achieve comparable
accuracy to VGG-16 in image classification on CIFAR-10 with fewer parameters
and less computational complexity.



Title: The Impact of Artificial Intelligence on the Evolution of Digital  Education: A Comparative Study of OpenAI Text Generation Tools including  ChatGPT, Bing Chat, Bard, and Ernie
In the digital era, the integration of artificial intelligence (AI) in
education has ushered in transformative changes, redefining teaching
methodologies, curriculum planning, and student engagement. This review paper
delves deep into the rapidly evolving landscape of digital education by
contrasting the capabilities and impact of OpenAI's pioneering text generation
tools like Bing Chat, Bard, Ernie with a keen focus on the novel ChatGPT.
Grounded in a typology that views education through the lenses of system,
process, and result, the paper navigates the multifaceted applications of AI.
From decentralizing global education and personalizing curriculums to digitally
documenting competence-based outcomes, AI stands at the forefront of
educational modernization. Highlighting ChatGPT's meteoric rise to one million
users in just five days, the study underscores its role in democratizing
education, fostering autodidacticism, and magnifying student engagement.
However, with such transformative power comes the potential for misuse, as
text-generation tools can inadvertently challenge academic integrity. By
juxtaposing the promise and pitfalls of AI in education, this paper advocates
for a harmonized synergy between AI tools and the educational community,
emphasizing the urgent need for ethical guidelines, pedagogical adaptations,
and strategic collaborations.



Title: Diffusion Generative Inverse Design
Inverse design refers to the problem of optimizing the input of an objective
function in order to enact a target outcome. For many real-world engineering
problems, the objective function takes the form of a simulator that predicts
how the system state will evolve over time, and the design challenge is to
optimize the initial conditions that lead to a target outcome. Recent
developments in learned simulation have shown that graph neural networks (GNNs)
can be used for accurate, efficient, differentiable estimation of simulator
dynamics, and support high-quality design optimization with gradient- or
sampling-based optimization procedures. However, optimizing designs from
scratch requires many expensive model queries, and these procedures exhibit
basic failures on either non-convex or high-dimensional problems.In this work,
we show how denoising diffusion models (DDMs) can be used to solve inverse
design problems efficiently and propose a particle sampling algorithm for
further improving their efficiency. We perform experiments on a number of fluid
dynamics design challenges, and find that our approach substantially reduces
the number of calls to the simulator compared to standard techniques.



Title: Enhance Multi-domain Sentiment Analysis of Review Texts through  Prompting Strategies
Large Language Models (LLMs) have made significant strides in both scientific
research and practical applications. Existing studies have demonstrated the
state-of-the-art (SOTA) performance of LLMs in various natural language
processing tasks. However, the question of how to further enhance LLMs'
performance in specific task using prompting strategies remains a pivotal
concern. This paper explores the enhancement of LLMs' performance in sentiment
analysis through the application of prompting strategies. We formulate the
process of prompting for sentiment analysis tasks and introduce two novel
strategies tailored for sentiment analysis: RolePlaying (RP) prompting and
Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT
prompting strategy which is a combination of RP prompting and CoT prompting. We
conduct comparative experiments on three distinct domain datasets to evaluate
the effectiveness of the proposed sentiment analysis strategies. The results
demonstrate that the adoption of the proposed prompting strategies leads to a
increasing enhancement in sentiment analysis accuracy. Further, the CoT
prompting strategy exhibits a notable impact on implicit sentiment analysis,
with the RP-CoT prompting strategy delivering the most superior performance
among all strategies.



Title: DeepVol: A Deep Transfer Learning Approach for Universal Asset  Volatility Modeling
This paper introduces DeepVol, a promising new deep learning volatility model
that outperforms traditional econometric models in terms of model generality.
DeepVol leverages the power of transfer learning to effectively capture and
model the volatility dynamics of all financial assets, including previously
unseen ones, using a single universal model. This contrasts to the prevailing
practice in econometrics literature, which necessitates training separate
models for individual datasets. The introduction of DeepVol opens up new
avenues for volatility modeling and forecasting in the finance industry,
potentially transforming the way volatility is understood and predicted.



Title: Dual Adversarial Alignment for Realistic Support-Query Shift Few-shot  Learning
Support-query shift few-shot learning aims to classify unseen examples (query
set) to labeled data (support set) based on the learned embedding in a
low-dimensional space under a distribution shift between the support set and
the query set. However, in real-world scenarios the shifts are usually unknown
and varied, making it difficult to estimate in advance. Therefore, in this
paper, we propose a novel but more difficult challenge, RSQS, focusing on
Realistic Support-Query Shift few-shot learning. The key feature of RSQS is
that the individual samples in a meta-task are subjected to multiple
distribution shifts in each meta-task. In addition, we propose a unified
adversarial feature alignment method called DUal adversarial ALignment
framework (DuaL) to relieve RSQS from two aspects, i.e., inter-domain bias and
intra-domain variance. On the one hand, for the inter-domain bias, we corrupt
the original data in advance and use the synthesized perturbed inputs to train
the repairer network by minimizing distance in the feature level. On the other
hand, for intra-domain variance, we proposed a generator network to synthesize
hard, i.e., less similar, examples from the support set in a self-supervised
manner and introduce regularized optimal transportation to derive a smooth
optimal transportation plan. Lastly, a benchmark of RSQS is built with several
state-of-the-art baselines among three datasets (CIFAR100, mini-ImageNet, and
Tiered-Imagenet). Experiment results show that DuaL significantly outperforms
the state-of-the-art methods in our benchmark.



Title: TensorBank:Tensor Lakehouse for Foundation Model Training
Storing and streaming high dimensional data for foundation model training
became a critical requirement with the rise of foundation models beyond natural
language. In this paper we introduce TensorBank, a petabyte scale tensor
lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU
memory at wire speed based on complex relational queries. We use Hierarchical
Statistical Indices (HSI) for query acceleration. Our architecture allows to
directly address tensors on block level using HTTP range reads. Once in GPU
memory, data can be transformed using PyTorch transforms. We provide a generic
PyTorch dataset type with a corresponding dataset factory translating
relational queries and requested transformations as an instance. By making use
of the HSI, irrelevant blocks can be skipped without reading them as those
indices contain statistics on their content at different hierarchical
resolution levels. This is an opinionated architecture powered by open
standards and making heavy use of open-source technology. Although, hardened
for production use using geospatial-temporal data, this architecture
generalizes to other use case like computer vision, computational neuroscience,
biological sequence analysis and more.



Title: Iterative Superquadric Recomposition of 3D Objects from Multiple Views
Humans are good at recomposing novel objects, i.e. they can identify
commonalities between unknown objects from general structure to finer detail,
an ability difficult to replicate by machines. We propose a framework, ISCO, to
recompose an object using 3D superquadrics as semantic parts directly from 2D
views without training a model that uses 3D supervision. To achieve this, we
optimize the superquadric parameters that compose a specific instance of the
object, comparing its rendered 3D view and 2D image silhouette. Our ISCO
framework iteratively adds new superquadrics wherever the reconstruction error
is high, abstracting first coarse regions and then finer details of the target
object. With this simple coarse-to-fine inductive bias, ISCO provides
consistent superquadrics for related object parts, despite not having any
semantic supervision. Since ISCO does not train any neural network, it is also
inherently robust to out-of-distribution objects. Experiments show that,
compared to recent single instance superquadrics reconstruction approaches,
ISCO provides consistently more accurate 3D reconstructions, even from images
in the wild. Code available at https://github.com/ExplainableML/ISCO .



Title: Improving Query-Focused Meeting Summarization with Query-Relevant  Knowledge
Query-Focused Meeting Summarization (QFMS) aims to generate a summary of a
given meeting transcript conditioned upon a query. The main challenges for QFMS
are the long input text length and sparse query-relevant information in the
meeting transcript. In this paper, we propose a knowledge-enhanced two-stage
framework called Knowledge-Aware Summarizer (KAS) to tackle the challenges. In
the first stage, we introduce knowledge-aware scores to improve the
query-relevant segment extraction. In the second stage, we incorporate
query-relevant knowledge in the summary generation. Experimental results on the
QMSum dataset show that our approach achieves state-of-the-art performance.
Further analysis proves the competency of our methods in generating relevant
and faithful summaries.



Title: Leveraging Label Information for Multimodal Emotion Recognition
Multimodal emotion recognition (MER) aims to detect the emotional status of a
given expression by combining the speech and text information. Intuitively,
label information should be capable of helping the model locate the salient
tokens/frames relevant to the specific emotion, which finally facilitates the
MER task. Inspired by this, we propose a novel approach for MER by leveraging
label information. Specifically, we first obtain the representative label
embeddings for both text and speech modalities, then learn the label-enhanced
text/speech representations for each utterance via label-token and label-frame
interactions. Finally, we devise a novel label-guided attentive fusion module
to fuse the label-aware text and speech representations for emotion
classification. Extensive experiments were conducted on the public IEMOCAP
dataset, and experimental results demonstrate that our proposed approach
outperforms existing baselines and achieves new state-of-the-art performance.



Title: Multi-label affordance mapping from egocentric vision
Accurate affordance detection and segmentation with pixel precision is an
important piece in many complex systems based on interactions, such as robots
and assitive devices. We present a new approach to affordance perception which
enables accurate multi-label segmentation. Our approach can be used to
automatically extract grounded affordances from first person videos of
interactions using a 3D map of the environment providing pixel level precision
for the affordance location. We use this method to build the largest and most
complete dataset on affordances based on the EPIC-Kitchen dataset, EPIC-Aff,
which provides interaction-grounded, multi-label, metric and spatial affordance
annotations. Then, we propose a new approach to affordance segmentation based
on multi-label detection which enables multiple affordances to co-exists in the
same space, for example if they are associated with the same object. We present
several strategies of multi-label detection using several segmentation
architectures. The experimental results highlight the importance of the
multi-label detection. Finally, we show how our metric representation can be
exploited for build a map of interaction hotspots in spatial action-centric
zones and use that representation to perform a task-oriented navigation.



Title: Exploring the Intersection of Complex Aesthetics and Generative AI for  Promoting Cultural Creativity in Rural China after the Post-Pandemic Era
This paper explores using generative AI and aesthetics to promote cultural
creativity in rural China amidst COVID-19's impact. Through literature reviews,
case studies, surveys, and text analysis, it examines art and technology
applications in rural contexts and identifies key challenges. The study finds
artworks often fail to resonate locally, while reliance on external artists
limits sustainability. Hence, nurturing grassroots "artist villagers" through
AI is proposed. Our approach involves training machine learning on subjective
aesthetics to generate culturally relevant content. Interactive AI media can
also boost tourism while preserving heritage. This pioneering research puts
forth original perspectives on the intersection of AI and aesthetics to
invigorate rural culture. It advocates holistic integration of technology and
emphasizes AI's potential as a creative enabler versus replacement. Ultimately,
it lays the groundwork for further exploration of leveraging AI innovations to
empower rural communities. This timely study contributes to growing interest in
emerging technologies to address critical issues facing rural China.



Title: Generalized Simplicial Attention Neural Networks
The aim of this work is to introduce Generalized Simplicial Attention Neural
Networks (GSANs), i.e., novel neural architectures designed to process data
defined on simplicial complexes using masked self-attentional layers. Hinging
on topological signal processing principles, we devise a series of
self-attention schemes capable of processing data components defined at
different simplicial orders, such as nodes, edges, triangles, and beyond. These
schemes learn how to weight the neighborhoods of the given topological domain
in a task-oriented fashion, leveraging the interplay among simplices of
different orders through the Dirac operator and its Dirac decomposition. We
also theoretically establish that GSANs are permutation equivariant and
simplicial-aware. Finally, we illustrate how our approach compares favorably
with other methods when applied to several (inductive and transductive) tasks
such as trajectory prediction, missing data imputation, graph classification,
and simplex prediction.



Title: Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR  data
Airborne LiDAR systems have the capability to capture the Earth's surface by
generating extensive point cloud data comprised of points mainly defined by 3D
coordinates. However, labeling such points for supervised learning tasks is
time-consuming. As a result, there is a need to investigate techniques that can
learn from unlabeled data to significantly reduce the number of annotated
samples. In this work, we propose to train a self-supervised encoder with
Barlow Twins and use it as a pre-trained network in the task of semantic scene
segmentation. The experimental results demonstrate that our unsupervised
pre-training boosts performance once fine-tuned on the supervised task,
especially for under-represented categories.



Title: A Lightweight, Rapid and Efficient Deep Convolutional Network for Chest  X-Ray Tuberculosis Detection
Tuberculosis (TB) is still recognized as one of the leading causes of death
worldwide. Recent advances in deep learning (DL) have shown to enhance
radiologists' ability to interpret chest X-ray (CXR) images accurately and with
fewer errors, leading to a better diagnosis of this disease. However, little
work has been done to develop models capable of diagnosing TB that offer good
performance while being efficient, fast and computationally inexpensive. In
this work, we propose LightTBNet, a novel lightweight, fast and efficient deep
convolutional network specially customized to detect TB from CXR images. Using
a total of 800 frontal CXR images from two publicly available datasets, our
solution yielded an accuracy, F1 and area under the ROC curve (AUC) of 0.906,
0.907 and 0.961, respectively, on an independent test subset. The proposed
model demonstrates outstanding performance while delivering a rapid prediction,
with minimal computational and memory requirements, making it highly suitable
for deployment in handheld devices that can be used in low-resource areas with
high TB prevalence. Code publicly available at
https://github.com/dani-capellan/LightTBNet.



Title: Making Large Language Models Better Reasoners with Alignment
Reasoning is a cognitive process of using evidence to reach a sound
conclusion. The reasoning capability is essential for large language models
(LLMs) to serve as the brain of the artificial general intelligence agent.
Recent studies reveal that fine-tuning LLMs on data with the chain of thought
(COT) reasoning process can significantly enhance their reasoning capabilities.
However, we find that the fine-tuned LLMs suffer from an \textit{Assessment
Misalignment} problem, i.e., they frequently assign higher scores to subpar
COTs, leading to potential limitations in their reasoning abilities. To address
this problem, we introduce an \textit{Alignment Fine-Tuning (AFT)} paradigm,
which involves three steps: 1) fine-tuning LLMs with COT training data; 2)
generating multiple COT responses for each question, and categorizing them into
positive and negative ones based on whether they achieve the correct answer; 3)
calibrating the scores of positive and negative responses given by LLMs with a
novel constraint alignment loss. Specifically, the constraint alignment loss
has two objectives: a) Alignment, which guarantees that positive scores surpass
negative scores to encourage answers with high-quality COTs; b) Constraint,
which keeps the negative scores confined to a reasonable range to prevent the
model degradation. Beyond just the binary positive and negative feedback, the
constraint alignment loss can be seamlessly adapted to the ranking situations
when ranking feedback is accessible. Furthermore, we also delve deeply into
recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and
discover that the constraint, which has been overlooked by these approaches, is
also crucial for their performance. Extensive experiments on four reasoning
benchmarks with both binary and ranking feedback demonstrate the effectiveness
of AFT.



Title: Model-based Offline Policy Optimization with Adversarial Network
Model-based offline reinforcement learning (RL), which builds a supervised
transition model with logging dataset to avoid costly interactions with the
online environment, has been a promising approach for offline policy
optimization. As the discrepancy between the logging data and online
environment may result in a distributional shift problem, many prior works have
studied how to build robust transition models conservatively and estimate the
model uncertainty accurately. However, the over-conservatism can limit the
exploration of the agent, and the uncertainty estimates may be unreliable. In
this work, we propose a novel Model-based Offline policy optimization framework
with Adversarial Network (MOAN). The key idea is to use adversarial learning to
build a transition model with better generalization, where an adversary is
introduced to distinguish between in-distribution and out-of-distribution
samples. Moreover, the adversary can naturally provide a quantification of the
model's uncertainty with theoretical guarantees. Extensive experiments showed
that our approach outperforms existing state-of-the-art baselines on widely
studied offline RL benchmarks. It can also generate diverse in-distribution
samples, and quantify the uncertainty more accurately.



Title: Dual Relation Alignment for Composed Image Retrieval
Composed image retrieval, a task involving the search for a target image
using a reference image and a complementary text as the query, has witnessed
significant advancements owing to the progress made in cross-modal modeling.
Unlike the general image-text retrieval problem with only one alignment
relation, i.e., image-text, we argue for the existence of two types of
relations in composed image retrieval. The explicit relation pertains to the
reference image & complementary text-target image, which is commonly exploited
by existing methods. Besides this intuitive relation, the observations during
our practice have uncovered another implicit yet crucial relation, i.e.,
reference image & target image-complementary text, since we found that the
complementary text can be inferred by studying the relation between the target
image and the reference image. Regrettably, existing methods largely focus on
leveraging the explicit relation to learn their networks, while overlooking the
implicit relation. In response to this weakness, We propose a new framework for
composed image retrieval, termed dual relation alignment, which integrates both
explicit and implicit relations to fully exploit the correlations among the
triplets. Specifically, we design a vision compositor to fuse reference image
and target image at first, then the resulted representation will serve two
roles: (1) counterpart for semantic alignment with the complementary text and
(2) compensation for the complementary text to boost the explicit relation
modeling, thereby implant the implicit relation into the alignment learning.
Our method is evaluated on two popular datasets, CIRR and FashionIQ, through
extensive experiments. The results confirm the effectiveness of our
dual-relation learning in substantially enhancing composed image retrieval
performance.



Title: BEVTrack: A Simple Baseline for Point Cloud Tracking in Bird's-Eye-View
3D single object tracking (SOT) in point clouds is still a challenging
problem due to appearance variation, distractors, and high sparsity of point
clouds. Notably, in autonomous driving scenarios, the target object typically
maintains spatial adjacency across consecutive frames, predominantly moving
horizontally. This spatial continuity offers valuable prior knowledge for
target localization. However, existing trackers, which often employ point-wise
representations, struggle to efficiently utilize this knowledge owing to the
irregular format of such representations. Consequently, they require elaborate
designs and solving multiple subtasks to establish spatial correspondence. In
this paper, we introduce BEVTrack, a simple yet strong baseline framework for
3D SOT. After converting consecutive point clouds into the common
Bird's-Eye-View representation, BEVTrack inherently encodes spatial proximity
and adeptly captures motion cues for tracking via a simple element-wise
operation and convolutional layers. Additionally, to better deal with objects
having diverse sizes and moving patterns, BEVTrack directly learns the
underlying motion distribution rather than making a fixed Laplacian or Gaussian
assumption as in previous works. Without bells and whistles, BEVTrack achieves
state-of-the-art performance on KITTI and NuScenes datasets while maintaining a
high inference speed of 122 FPS. The code will be released at
https://github.com/xmm-prio/BEVTrack.



Title: AniPortraitGAN: Animatable 3D Portrait Generation from 2D Image  Collections
Previous animatable 3D-aware GANs for human generation have primarily focused
on either the human head or full body. However, head-only videos are relatively
uncommon in real life, and full body generation typically does not deal with
facial expression control and still has challenges in generating high-quality
results. Towards applicable video avatars, we present an animatable 3D-aware
GAN that generates portrait images with controllable facial expression, head
pose, and shoulder movements. It is a generative model trained on unstructured
2D image collections without using 3D or video data. For the new task, we base
our method on the generative radiance manifold representation and equip it with
learnable facial and head-shoulder deformations. A dual-camera rendering and
adversarial learning scheme is proposed to improve the quality of the generated
faces, which is critical for portrait images. A pose deformation processing
network is developed to generate plausible deformations for challenging regions
such as long hair. Experiments show that our method, trained on unstructured 2D
images, can generate diverse and high-quality 3D portraits with desired control
over different properties.



Title: Leveraging BERT Language Models for Multi-Lingual ESG Issue  Identification
Environmental, Social, and Governance (ESG) has been used as a metric to
measure the negative impacts and enhance positive outcomes of companies in
areas such as the environment, society, and governance. Recently, investors
have increasingly recognized the significance of ESG criteria in their
investment choices, leading businesses to integrate ESG principles into their
operations and strategies. The Multi-Lingual ESG Issue Identification (ML-ESG)
shared task encompasses the classification of news documents into 35 distinct
ESG issue labels. In this study, we explored multiple strategies harnessing
BERT language models to achieve accurate classification of news documents
across these labels. Our analysis revealed that the RoBERTa classifier emerged
as one of the most successful approaches, securing the second-place position
for the English test dataset, and sharing the fifth-place position for the
French test dataset. Furthermore, our SVM-based binary model tailored for the
Chinese language exhibited exceptional performance, earning the second-place
rank on the test dataset.



Title: Exchanging-based Multimodal Fusion with Transformer
We study the problem of multimodal fusion in this paper. Recent
exchanging-based methods have been proposed for vision-vision fusion, which aim
to exchange embeddings learned from one modality to the other. However, most of
them project inputs of multimodalities into different low-dimensional spaces
and cannot be applied to the sequential input data. To solve these issues, in
this paper, we propose a novel exchanging-based multimodal fusion model MuSE
for text-vision fusion based on Transformer. We first use two encoders to
separately map multimodal inputs into different low-dimensional spaces. Then we
employ two decoders to regularize the embeddings and pull them into the same
space. The two decoders capture the correlations between texts and images with
the image captioning task and the text-to-image generation task, respectively.
Further, based on the regularized embeddings, we present CrossTransformer,
which uses two Transformer encoders with shared parameters as the backbone
model to exchange knowledge between multimodalities. Specifically,
CrossTransformer first learns the global contextual information of the inputs
in the shallow layers. After that, it performs inter-modal exchange by
selecting a proportion of tokens in one modality and replacing their embeddings
with the average of embeddings in the other modality. We conduct extensive
experiments to evaluate the performance of MuSE on the Multimodal Named Entity
Recognition task and the Multimodal Sentiment Analysis task. Our results show
the superiority of MuSE against other competitors. Our code and data are
provided at https://github.com/RecklessRonan/MuSE.



Title: Improving equilibrium propagation without weight symmetry through  Jacobian homeostasis
Equilibrium propagation (EP) is a compelling alternative to the
backpropagation of error algorithm (BP) for computing gradients of neural
networks on biological or analog neuromorphic substrates. Still, the algorithm
requires weight symmetry and infinitesimal equilibrium perturbations, i.e.,
nudges, to estimate unbiased gradients efficiently. Both requirements are
challenging to implement in physical systems. Yet, whether and how weight
asymmetry affects its applicability is unknown because, in practice, it may be
masked by biases introduced through the finite nudge. To address this question,
we study generalized EP, which can be formulated without weight symmetry, and
analytically isolate the two sources of bias. For complex-differentiable
non-symmetric networks, we show that the finite nudge does not pose a problem,
as exact derivatives can still be estimated via a Cauchy integral. In contrast,
weight asymmetry introduces bias resulting in low task performance due to poor
alignment of EP's neuronal error vectors compared to BP. To mitigate this
issue, we present a new homeostatic objective that directly penalizes
functional asymmetries of the Jacobian at the network's fixed point. This
homeostatic objective dramatically improves the network's ability to solve
complex tasks such as ImageNet 32x32. Our results lay the theoretical
groundwork for studying and mitigating the adverse effects of imperfections of
physical networks on learning algorithms that rely on the substrate's
relaxation dynamics.



Title: Dense Object Grounding in 3D Scenes
Localizing objects in 3D scenes according to the semantics of a given natural
language is a fundamental yet important task in the field of multimedia
understanding, which benefits various real-world applications such as robotics
and autonomous driving. However, the majority of existing 3D object grounding
methods are restricted to a single-sentence input describing an individual
object, which cannot comprehend and reason more contextualized descriptions of
multiple objects in more practical 3D cases. To this end, we introduce a new
challenging task, called 3D Dense Object Grounding (3D DOG), to jointly
localize multiple objects described in a more complicated paragraph rather than
a single sentence. Instead of naively localizing each sentence-guided object
independently, we found that dense objects described in the same paragraph are
often semantically related and spatially located in a focused region of the 3D
scene. To explore such semantic and spatial relationships of densely referred
objects for more accurate localization, we propose a novel Stacked Transformer
based framework for 3D DOG, named 3DOGSFormer. Specifically, we first devise a
contextual query-driven local transformer decoder to generate initial grounding
proposals for each target object. Then, we employ a proposal-guided global
transformer decoder that exploits the local object features to learn their
correlation for further refining initial grounding proposals. Extensive
experiments on three challenging benchmarks (Nr3D, Sr3D, and ScanRefer) show
that our proposed 3DOGSFormer outperforms state-of-the-art 3D single-object
grounding methods and their dense-object variants by significant margins.



Title: DCP-Net: A Distributed Collaborative Perception Network for Remote  Sensing Semantic Segmentation
Onboard intelligent processing is widely applied in emergency tasks in the
field of remote sensing. However, it is predominantly confined to an individual
platform with a limited observation range as well as susceptibility to
interference, resulting in limited accuracy. Considering the current state of
multi-platform collaborative observation, this article innovatively presents a
distributed collaborative perception network called DCP-Net. Firstly, the
proposed DCP-Net helps members to enhance perception performance by integrating
features from other platforms. Secondly, a self-mutual information match module
is proposed to identify collaboration opportunities and select suitable
partners, prioritizing critical collaborative features and reducing redundant
transmission cost. Thirdly, a related feature fusion module is designed to
address the misalignment between local and collaborative features, improving
the quality of fused features for the downstream task. We conduct extensive
experiments and visualization analyses using three semantic segmentation
datasets, including Potsdam, iSAID and DFC23. The results demonstrate that
DCP-Net outperforms the existing methods comprehensively, improving mIoU by
2.61%~16.89% at the highest collaboration efficiency, which promotes the
performance to a state-of-the-art level.



Title: FSD: An Initial Chinese Dataset for Fake Song Detection
Singing voice synthesis and singing voice conversion have significantly
advanced, revolutionizing musical experiences. However, the rise of "Deepfake
Songs" generated by these technologies raises concerns about authenticity.
Unlike Audio DeepFake Detection (ADD), the field of song deepfake detection
lacks specialized datasets or methods for song authenticity verification. In
this paper, we initially construct a Chinese Fake Song Detection (FSD) dataset
to investigate the field of song deepfake detection. The fake songs in the FSD
dataset are generated by five state-of-the-art singing voice synthesis and
singing voice conversion methods. Our initial experiments on FSD revealed the
ineffectiveness of existing speech-trained ADD models for the task of Song
DeepFake Detection. Thus, we employ the FSD dataset for the training of ADD
models. We subsequently evaluate these models under two scenarios: one with the
original songs and another with separated vocal tracks. Experiment results show
that song-trained ADD models exhibit an approximate 38.58% reduction in average
equal error rate compared to speech-trained ADD models on the FSD test set.



Title: Augmenting Black-box LLMs with Medical Textbooks for Clinical Question  Answering
Large-scale language models (LLMs), such as ChatGPT, are capable of
generating human-like responses for various downstream tasks, such as
task-oriented dialogues and question answering. However, applying LLMs to
medical domains remains challenging due to their inability to leverage
domain-specific knowledge. In this study, we present the Large-scale Language
Models Augmented with Medical Textbooks (LLM-AMT), which integrates
authoritative medical textbooks as the cornerstone of its design, enhancing its
proficiency in the specialized domain through plug-and-play modules, comprised
of a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM
Reader. Experimental evaluation on three open-domain medical question-answering
tasks reveals a substantial enhancement in both the professionalism and
accuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement
ranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that
medical textbooks as the retrieval corpus serves as a more valuable external
knowledge source than Wikipedia in the medical domain. Our experiments show
that textbook augmentation results in a performance improvement ranging from
9.7% to 12.2% over Wikipedia augmentation.



Title: Distributionally Robust Model-based Reinforcement Learning with Large  State Spaces
Three major challenges in reinforcement learning are the complex dynamical
systems with large state spaces, the costly data acquisition processes, and the
deviation of real-world dynamics from the training environment deployment. To
overcome these issues, we study distributionally robust Markov decision
processes with continuous state spaces under the widely used Kullback-Leibler,
chi-square, and total variation uncertainty sets. We propose a model-based
approach that utilizes Gaussian Processes and the maximum variance reduction
algorithm to efficiently learn multi-output nominal transition dynamics,
leveraging access to a generative model (i.e., simulator). We further
demonstrate the statistical sample complexity of the proposed method for
different uncertainty sets. These complexity bounds are independent of the
number of states and extend beyond linear dynamics, ensuring the effectiveness
of our approach in identifying near-optimal distributionally-robust policies.
The proposed method can be further combined with other model-free
distributionally robust reinforcement learning methods to obtain a near-optimal
robust policy. Experimental results demonstrate the robustness of our algorithm
to distributional shifts and its superior performance in terms of the number of
samples needed.



Title: Encoding Seasonal Climate Predictions for Demand Forecasting with  Modular Neural Network
Current time-series forecasting problems use short-term weather attributes as
exogenous inputs. However, in specific time-series forecasting solutions (e.g.,
demand prediction in the supply chain), seasonal climate predictions are
crucial to improve its resilience. Representing mid to long-term seasonal
climate forecasts is challenging as seasonal climate predictions are uncertain,
and encoding spatio-temporal relationship of climate forecasts with demand is
complex. We propose a novel modeling framework that efficiently encodes seasonal
climate predictions to provide robust and reliable time-series forecasting for
supply chain functions. The encoding framework enables effective learning of
latent representations -- be it uncertain seasonal climate prediction or other
time-series data (e.g., buyer patterns) -- via a modular neural network
architecture. Our extensive experiments indicate that learning such
representations to model seasonal climate forecast results in an error
reduction of approximately 13\% to 17\% across multiple real-world data sets
compared to existing demand forecasting methods.



Title: MA-VAE: Multi-head Attention-based Variational Autoencoder Approach for  Anomaly Detection in Multivariate Time-series Applied to Automotive Endurance  Powertrain Testing
A clear need for automatic anomaly detection applied to automotive testing
has emerged as more and more attention is paid to the data recorded and manual
evaluation by humans reaches its capacity. Such real-world data is massive,
diverse, multivariate and temporal in nature, therefore requiring modelling of
the testee behaviour. We propose a variational autoencoder with multi-head
attention (MA-VAE), which, when trained on unlabelled data, not only provides
very few false positives but also manages to detect the majority of the
anomalies presented. In addition to that, the approach offers a novel way to
avoid the bypass phenomenon, an undesirable behaviour investigated in
literature. Lastly, the approach also introduces a new method to remap
individual windows to a continuous time series. The results are presented in
the context of a real-world industrial data set and several experiments are
undertaken to further investigate certain aspects of the proposed model. When
configured properly, it is 9% of the time wrong when an anomaly is flagged and
discovers 67% of the anomalies present. Also, MA-VAE has the potential to
perform well with only a fraction of the training and validation subset,
however, to extract it, a more sophisticated threshold estimation method is
required.



Title: s-ID: Causal Effect Identification in a Sub-Population
Causal inference in a sub-population involves identifying the causal effect
of an intervention on a specific subgroup within a larger population. However,
ignoring the subtleties introduced by sub-populations can either lead to
erroneous inference or limit the applicability of existing methods. We
introduce and advocate for a causal inference problem in sub-populations
(henceforth called s-ID), in which we merely have access to observational data
of the targeted sub-population (as opposed to the entire population). Existing
inference problems in sub-populations operate on the premise that the given
data distributions originate from the entire population, thus, cannot tackle
the s-ID problem. To address this gap, we provide necessary and sufficient
conditions that must hold in the causal graph for a causal effect in a
sub-population to be identifiable from the observational distribution of that
sub-population. Given these conditions, we present a sound and complete
algorithm for the s-ID problem.



Title: Graph Self-Contrast Representation Learning
Graph contrastive learning (GCL) has recently emerged as a promising approach
for graph representation learning. Some existing methods adopt the 1-vs-K
scheme to construct one positive and K negative samples for each graph, but it
is difficult to set K. For those methods that do not use negative samples, it
is often necessary to add additional strategies to avoid model collapse, which
could only alleviate the problem to some extent. All these drawbacks will
undoubtedly have an adverse impact on the generalizability and efficiency of
the model. In this paper, to address these issues, we propose a novel graph
self-contrast framework GraphSC, which only uses one positive and one negative
sample, and chooses triplet loss as the objective. Specifically, self-contrast
has two implications. First, GraphSC generates both positive and negative views
of a graph sample from the graph itself via graph augmentation functions of
various intensities, and use them for self-contrast. Second, GraphSC uses
Hilbert-Schmidt Independence Criterion (HSIC) to factorize the representations
into multiple factors and proposes a masked self-contrast mechanism to better
separate positive and negative samples. Further, Since the triplet loss only
optimizes the relative distance between the anchor and its positive/negative
samples, it is difficult to ensure the absolute distance between the anchor and
positive sample. Therefore, we explicitly reduced the absolute distance between
the anchor and positive sample to accelerate convergence. Finally, we conduct
extensive experiments to evaluate the performance of GraphSC against 19 other
state-of-the-art methods in both unsupervised and transfer learning settings.



Title: SeisCLIP: A seismology foundation model pre-trained by multi-modal data  for multi-purpose seismic feature extraction
Training specific deep learning models for particular tasks is common across
various domains within seismology. However, this approach encounters two
limitations: inadequate labeled data for certain tasks and limited
generalization across regions. To address these challenges, we develop
SeisCLIP, a seismology foundation model trained through contrastive learning
from multi-modal data. It consists of a transformer encoder for extracting
crucial features from time-frequency seismic spectrum and an MLP encoder for
integrating the phase and source information of the same event. These encoders
are jointly pre-trained on a vast dataset and the spectrum encoder is
subsequently fine-tuned on smaller datasets for various downstream tasks.
Notably, SeisCLIP's performance surpasses that of baseline methods in event
classification, localization, and focal mechanism analysis tasks, employing
distinct datasets from different regions. In conclusion, SeisCLIP holds
significant potential as a foundational model in the field of seismology,
paving the way for innovative directions in foundation-model-based seismology
research.



Title: Revisiting File Context for Source Code Summarization
Source code summarization is the task of writing natural language
descriptions of source code. A typical use case is generating short summaries
of subroutines for use in API documentation. The heart of almost all current
research into code summarization is the encoder-decoder neural architecture,
and the encoder input is almost always a single subroutine or other short code
snippet. The problem with this setup is that the information needed to describe
the code is often not present in the code itself -- that information often
resides in other nearby code. In this paper, we revisit the idea of ``file
context'' for code summarization. File context is the idea of encoding select
information from other subroutines in the same file. We propose a novel
modification of the Transformer architecture that is purpose-built to encode
file context and demonstrate its improvement over several baselines. We find
that file context helps on a subset of challenging examples where traditional
approaches struggle.



Title: Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe  Self-Driving in Non-Stationary Environments
In the area of learning-driven artificial intelligence advancement, the
integration of machine learning (ML) into self-driving (SD) technology stands
as an impressive engineering feat. Yet, in real-world applications outside the
confines of controlled laboratory scenarios, the deployment of self-driving
technology assumes a life-critical role, necessitating heightened attention
from researchers towards both safety and efficiency. To illustrate, when a
self-driving model encounters an unfamiliar environment in real-time execution,
the focus must not solely revolve around enhancing its anticipated performance;
equal consideration must be given to ensuring its execution or real-time
adaptation maintains a requisite level of safety. This study introduces an
algorithm for online meta-reinforcement learning, employing lookahead symbolic
constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning}
(NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes the
efficiency of online adaptations with the overarching goal of ensuring
long-term safety. Experimental results demonstrate NUMERLA confers the
self-driving agent with the capacity for real-time adaptability, leading to
safe and self-adaptive driving under non-stationary urban human-vehicle
interaction scenarios.



Title: Information Processing by Neuron Populations in the Central Nervous  System: Mathematical Structure of Data and Operations
In the intricate architecture of the mammalian central nervous system,
neurons form populations. Axonal bundles communicate between these clusters
using spike trains as their medium. However, these neuron populations' precise
encoding and operations have yet to be discovered. In our analysis, the
starting point is a state-of-the-art mechanistic model of a generic neuron
endowed with plasticity. From this simple framework emerges a profound
mathematical construct: The representation and manipulation of information can
be precisely characterized by an algebra of finite convex cones. Furthermore,
these neuron populations are not merely passive transmitters. They act as
operators within this algebraic structure, mirroring the functionality of a
low-level programming language. When these populations interconnect, they
embody succinct yet potent algebraic expressions. These networks allow them to
implement many operations, such as specialization, generalization, novelty
detection, dimensionality reduction, inverse modeling, prediction, and
associative memory. In broader terms, this work illuminates the potential of
matrix embeddings in advancing our understanding in fields like cognitive
science and AI. These embeddings enhance the capacity for concept processing
and hierarchical description over their vector counterparts.



Title: Building a Winning Team: Selecting Source Model Ensembles using a  Submodular Transferability Estimation Approach
Estimating the transferability of publicly available pretrained models to a
target task has assumed an important place for transfer learning tasks in
recent years. Existing efforts propose metrics that allow a user to choose one
model from a pool of pre-trained models without having to fine-tune each model
individually and identify one explicitly. With the growth in the number of
available pre-trained models and the popularity of model ensembles, it also
becomes essential to study the transferability of multiple-source models for a
given target task. The few existing efforts study transferability in such
multi-source ensemble settings using just the outputs of the classification
layer and neglect possible domain or task mismatch. Moreover, they overlook the
most important factor while selecting the source models, viz., the cohesiveness
factor between them, which can impact the performance and confidence in the
prediction of the ensemble. To address these gaps, we propose a novel Optimal
tranSport-based suBmOdular tRaNsferability metric (OSBORN) to estimate the
transferability of an ensemble of models to a downstream task. OSBORN
collectively accounts for image domain difference, task difference, and
cohesiveness of models in the ensemble to provide reliable estimates of
transferability. We gauge the performance of OSBORN on both image
classification and semantic segmentation tasks. Our setup includes 28 source
datasets, 11 target datasets, 5 model architectures, and 2 pre-training
methods. We benchmark our method against current state-of-the-art metrics
MS-LEEP and E-LEEP, and outperform them consistently using the proposed
approach.



Title: Efficient RL via Disentangled Environment and Agent Representations
Agents that are aware of the separation between themselves and their
environments can leverage this understanding to form effective representations
of visual input. We propose an approach for learning such structured
representations for RL algorithms, using visual knowledge of the agent, such as
its shape or mask, which is often inexpensive to obtain. This is incorporated
into the RL objective using a simple auxiliary loss. We show that our method,
Structured Environment-Agent Representations, outperforms state-of-the-art
model-free approaches over 18 different challenging visual simulation
environments spanning 5 different robots. Website at https://sear-rl.github.io/



